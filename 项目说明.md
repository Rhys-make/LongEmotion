# LongEmotion 项目技术说明

## 项目概览

这是一个完整的机器学习竞赛方案，针对 Hugging Face 上的 LongEmotion 数据集实现了五个情感相关任务。

### 技术栈

- **深度学习框架**: PyTorch 2.0+
- **Transformers**: Hugging Face Transformers 4.35+
- **Web 框架**: FastAPI 0.104+
- **数据处理**: Datasets, Pandas, NumPy
- **评估**: scikit-learn, rouge-score

### 核心架构

```
输入文本
   ↓
预处理 (utils/preprocess.py)
   ↓
模型推理 (models/*.py)
   ↓
后处理 & 评估 (utils/evaluator.py)
   ↓
输出结果
```

## 五个任务详解

### 1. 情感分类 (Emotion Classification)

**任务**: 将文本分类到 7 种情感类别之一

**模型架构**:
```
BERT Encoder
    ↓
[CLS] Token
    ↓
Linear Layer (768 → 7)
    ↓
Softmax
    ↓
单标签预测
```

**关键代码**: `models/classification_model.py`

**示例**:
```python
输入: "今天天气真好！"
输出: {"emotion": "happiness", "confidence": 0.95}
```

### 2. 情感检测 (Emotion Detection)

**任务**: 检测文本中存在的多个情感（多标签分类）

**模型架构**:
```
BERT Encoder
    ↓
[CLS] Token
    ↓
MLP (768 → 384 → 7)
    ↓
Sigmoid
    ↓
多标签预测 (threshold=0.5)
```

**关键代码**: `models/detection_model.py`

**示例**:
```python
输入: "这部电影让我又高兴又难过"
输出: {"emotions": [
    {"emotion": "happiness", "score": 0.75},
    {"emotion": "sadness", "score": 0.82}
]}
```

### 3. 情感对话 (Emotion Conversation)

**任务**: 根据上下文和目标情感生成对话回复

**模型架构**:
```
Qwen2/ChatGLM (Causal LM)
    ↓
Prompt: "作为理解情感的助手，以{emotion}情感回复..."
    ↓
Context: {对话上下文}
    ↓
Generation (temperature=0.7, top_p=0.9)
    ↓
生成的回复
```

**关键代码**: `models/conversation_model.py`

**示例**:
```python
输入: {"context": "我今天考试失败了", "emotion": "happiness"}
输出: {"response": "别灰心！失败是成功之母，下次一定能考好！"}
```

### 4. 情感摘要 (Emotion Summary)

**任务**: 生成文本的情感摘要

**模型架构**:
```
mT5 Encoder-Decoder
    ↓
Input: "summarize: {long_text}"
    ↓
Beam Search (num_beams=4)
    ↓
生成的摘要
```

**关键代码**: `models/summary_model.py`

**示例**:
```python
输入: "今天发生了很多事情...（长文本）"
输出: {"summary": "今天经历了喜悦和挫折，总体心情复杂"}
```

### 5. 情感问答 (Emotion QA)

**任务**: 从上下文中抽取问题的答案

**模型架构**:
```
BERT Encoder
    ↓
Question + Context
    ↓
Start/End Position Prediction
    ↓
Span Extraction
    ↓
答案文本
```

**关键代码**: `models/qa_model.py`

**示例**:
```python
输入: {"question": "主人公的情感？", "context": "他很快乐..."}
输出: {"answer": "快乐", "confidence": 0.88}
```

## 训练流程

### 数据流

```
Hugging Face Dataset
    ↓
load_from_disk()
    ↓
TextPreprocessor.process_*()
    ↓
DataLoader (with collate_fn)
    ↓
UnifiedTrainer.train()
    ↓
保存最佳模型
```

### 训练器特性

**UnifiedTrainer** (`utils/trainer.py`) 提供：

1. **自动保存最佳模型**
   - 基于验证集指标
   - 支持自定义指标（loss/accuracy/f1）

2. **早停机制**
   - 默认耐心值: 3 轮
   - 防止过拟合

3. **学习率调度**
   - Warmup: 10% 训练步数
   - 线性衰减

4. **梯度管理**
   - 梯度裁剪（max_norm=1.0）
   - 防止梯度爆炸

5. **日志记录**
   - 训练/验证损失
   - 评估指标
   - 保存到 JSON

### 评估指标

**Evaluator** (`utils/evaluator.py`) 支持：

| 任务 | 指标 |
|-----|------|
| Classification | Accuracy, Precision, Recall, F1 |
| Detection | Micro-F1, Macro-F1 |
| Conversation | ROUGE-1, ROUGE-2, ROUGE-L |
| Summary | ROUGE-1, ROUGE-2, ROUGE-L |
| QA | Exact Match, ROUGE |

## API 设计

### 架构模式

```
FastAPI Server
    ↓
ModelManager (Lazy Loading)
    ↓
┌─────────┬─────────┬─────────┬─────────┬─────────┐
│ Classify│ Detect  │ Conv    │ Summary │   QA    │
└─────────┴─────────┴─────────┴─────────┴─────────┘
    ↓           ↓         ↓         ↓         ↓
  Model 1    Model 2   Model 3   Model 4   Model 5
```

### 延迟加载

模型在首次调用时加载，减少启动时间和内存占用：

```python
@property
def classification_model(self):
    if self._classification_model is None:
        self._classification_model = load_model()
    return self._classification_model
```

### 请求/响应模式

所有 API 使用 Pydantic 模型进行验证：

```python
class TextRequest(BaseModel):
    text: str

class ClassificationResponse(BaseModel):
    label: int
    emotion: str
    confidence: float
    probabilities: dict
```

### API 路由

| 端点 | 方法 | 任务 | 批量支持 |
|-----|------|-----|---------|
| `/classify` | POST | 分类 | ✓ |
| `/detect` | POST | 检测 | ✓ |
| `/conversation` | POST | 对话 | ✗ |
| `/summary` | POST | 摘要 | ✓ |
| `/qa` | POST | 问答 | ✗ |

## 配置管理

### 全局配置 (`config.py`)

```python
MODEL_CONFIGS = {
    "classification": {
        "model_name": "bert-base-chinese",
        "num_labels": 7,
        "learning_rate": 2e-5,
        ...
    },
    ...
}
```

### 情感标签

```python
EMOTION_LABELS = [
    "happiness",  # 0
    "sadness",    # 1
    "anger",      # 2
    "fear",       # 3
    "surprise",   # 4
    "disgust",    # 5
    "neutral"     # 6
]
```

## 优化技巧

### 内存优化

1. **梯度检查点** (Gradient Checkpointing)
   ```python
   model.gradient_checkpointing_enable()
   ```

2. **混合精度训练** (Mixed Precision)
   ```python
   from torch.cuda.amp import autocast, GradScaler
   ```

3. **8-bit 量化**
   ```python
   model = AutoModel.from_pretrained(..., load_in_8bit=True)
   ```

### 速度优化

1. **批量推理**
   - 使用 `batch_generate()` 而非循环
   - DataLoader 并行加载

2. **模型缓存**
   - 预加载常用模型
   - 使用模型池

3. **异步处理**
   - FastAPI 异步路由
   - 后台任务队列

### 精度优化

1. **数据增强**
   - 回译（Back Translation）
   - 同义词替换
   - EDA (Easy Data Augmentation)

2. **模型集成**
   - 投票法 (Voting)
   - 加权平均 (Weighted Average)
   - Stacking

3. **对抗训练**
   - FGM (Fast Gradient Method)
   - PGD (Projected Gradient Descent)

## 扩展指南

### 添加新任务

1. **创建模型类** (`models/new_task_model.py`)
   ```python
   class NewTaskModel:
       def __init__(self, ...): ...
       def predict(self, ...): ...
       def save(self, ...): ...
       @classmethod
       def load(cls, ...): ...
   ```

2. **添加训练逻辑** (`scripts/train_all.py`)
   ```python
   def train_new_task(self, ...):
       # 加载数据
       # 初始化模型
       # 训练
       # 保存
   ```

3. **添加推理逻辑** (`scripts/inference_all.py`)
   ```python
   def infer_new_task(self, ...):
       # 加载模型
       # 推理
       # 保存结果
   ```

4. **添加 API 路由** (`api/main.py`)
   ```python
   @app.post("/new_task")
   async def new_task(request: Request):
       # 调用模型
       # 返回结果
   ```

### 自定义预处理

在 `utils/preprocess.py` 中添加：

```python
def custom_clean(self, text: str) -> str:
    # 自定义清洗逻辑
    return processed_text
```

### 自定义评估指标

在 `utils/evaluator.py` 中添加：

```python
def compute_custom_metrics(self, predictions, labels):
    # 自定义指标计算
    return metrics
```

## 性能基准

### 训练时间（单卡 GPU）

| 任务 | 模型大小 | 训练时间 | 显存占用 |
|-----|---------|---------|---------|
| Classification | 110M | ~30 min | ~4 GB |
| Detection | 110M | ~30 min | ~4 GB |
| Conversation | 1.5B | ~2 hours | ~12 GB |
| Summary | 580M | ~1 hour | ~8 GB |
| QA | 110M | ~40 min | ~6 GB |

### 推理速度（单样本）

| 任务 | 延迟 (CPU) | 延迟 (GPU) |
|-----|-----------|-----------|
| Classification | ~50ms | ~5ms |
| Detection | ~50ms | ~5ms |
| Conversation | ~2s | ~200ms |
| Summary | ~500ms | ~50ms |
| QA | ~80ms | ~8ms |

## 故障排除

### 常见错误及解决方案

1. **`RuntimeError: CUDA out of memory`**
   - 减小批量大小
   - 启用梯度检查点
   - 使用 CPU

2. **`ModuleNotFoundError: No module named 'xxx'`**
   - 重新安装依赖: `pip install -r requirements.txt`
   - 检查虚拟环境

3. **`ValueError: Expected input batch_size`**
   - 检查数据格式
   - 确认 collate_fn 正确

4. **API 返回 500 错误**
   - 检查模型路径
   - 查看服务器日志
   - 确认模型已训练

## 最佳实践

### 开发流程

1. **小数据验证** → 在小数据集上测试代码
2. **单任务调试** → 逐个任务验证
3. **全量训练** → 确认无误后全量训练
4. **集成测试** → 测试 API 和推理脚本

### 代码规范

- 使用类型提示 (Type Hints)
- 编写文档字符串 (Docstrings)
- 保持函数简洁 (<50 行)
- 使用有意义的变量名

### Git 工作流

```bash
# 创建功能分支
git checkout -b feature/new-task

# 提交更改
git add .
git commit -m "feat: 添加新任务支持"

# 合并到主分支
git checkout main
git merge feature/new-task
```

## 参考文献

- BERT: Devlin et al. (2018)
- GPT: Radford et al. (2018)
- T5: Raffel et al. (2019)
- FastAPI: https://fastapi.tiangolo.com
- Hugging Face: https://huggingface.co

## 许可证

MIT License - 详见 LICENSE 文件

---

**项目维护者**: LongEmotion Team  
**最后更新**: 2024  
**版本**: 1.0.0

