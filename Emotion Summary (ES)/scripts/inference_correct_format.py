# -*- coding: utf-8 -*-
"""æ­£ç¡®æ ¼å¼çš„æ¨ç†è„šæœ¬ - ç”Ÿæˆæ¯”èµ›è¦æ±‚çš„5ä¸ªå­—æ®µ"""

import json
from pathlib import Path
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
from tqdm import tqdm

def create_structured_prompt(case_desc, consult_process):
    """åˆ›å»ºç»“æ„åŒ–çš„promptï¼Œå¼•å¯¼æ¨¡å‹ç”Ÿæˆ5ä¸ªå­—æ®µ"""
    
    # å°†åˆ—è¡¨è½¬ä¸ºæ–‡æœ¬
    case_text = " ".join(case_desc) if isinstance(case_desc, list) else case_desc
    consult_text = " ".join(consult_process) if isinstance(consult_process, list) else consult_process
    
    # æˆªæ–­ä»¥é€‚åº”æ¨¡å‹é•¿åº¦é™åˆ¶
    case_text = case_text[:500]
    consult_text = consult_text[:1500]
    
    # åˆ›å»ºç»“æ„åŒ–prompt
    prompt = f"""Analyze this psychological counseling case and provide 5 specific summaries:

Case Description: {case_text}

Consultation Process: {consult_text}

Please provide:
1. Cause (ç—…å› ):
2. Symptoms (ç—‡çŠ¶):
3. Treatment Process (æ²»ç–—è¿‡ç¨‹):
4. Illness Characteristics (ç–¾ç—…ç‰¹å¾):
5. Treatment Effect (æ²»ç–—æ•ˆæœ):"""
    
    return prompt

def parse_model_output(generated_text):
    """ä»æ¨¡å‹è¾“å‡ºä¸­æå–5ä¸ªå­—æ®µ"""
    
    # åˆå§‹åŒ–5ä¸ªå­—æ®µ
    result = {
        "predicted_cause": "",
        "predicted_symptoms": "",
        "predicted_treatment_process": "",
        "predicted_illness_Characteristics": "",
        "predicted_treatment_effect": ""
    }
    
    # ç®€å•è§£æï¼šå¦‚æœæ¨¡å‹è¾“å‡ºåŒ…å«æ ‡è®°ï¼Œå°±æå–
    lines = generated_text.split('\n')
    current_field = None
    
    for line in lines:
        line = line.strip()
        if 'cause' in line.lower() or 'ç—…å› ' in line or '1.' in line:
            current_field = 'predicted_cause'
        elif 'symptom' in line.lower() or 'ç—‡çŠ¶' in line or '2.' in line:
            current_field = 'predicted_symptoms'
        elif 'treatment process' in line.lower() or 'æ²»ç–—è¿‡ç¨‹' in line or '3.' in line:
            current_field = 'predicted_treatment_process'
        elif 'characteristic' in line.lower() or 'ç–¾ç—…ç‰¹å¾' in line or '4.' in line:
            current_field = 'predicted_illness_Characteristics'
        elif 'effect' in line.lower() or 'æ²»ç–—æ•ˆæœ' in line or '5.' in line:
            current_field = 'predicted_treatment_effect'
        elif current_field and line:
            # æ·»åŠ å†…å®¹åˆ°å½“å‰å­—æ®µ
            if result[current_field]:
                result[current_field] += " " + line
            else:
                result[current_field] = line
    
    # å¦‚æœæ²¡æœ‰æˆåŠŸè§£æï¼Œå°±æŠŠæ•´ä¸ªæ–‡æœ¬æ”¾å…¥ç¬¬ä¸€ä¸ªå­—æ®µ
    if not any(result.values()):
        result["predicted_cause"] = generated_text[:200] if len(generated_text) > 200 else generated_text
        result["predicted_symptoms"] = generated_text[:200] if len(generated_text) > 200 else generated_text
        result["predicted_treatment_process"] = generated_text[:200] if len(generated_text) > 200 else generated_text
        result["predicted_illness_Characteristics"] = generated_text[:200] if len(generated_text) > 200 else generated_text
        result["predicted_treatment_effect"] = generated_text[:200] if len(generated_text) > 200 else generated_text
    
    return result

def main():
    print("="*70)
    print("ç”Ÿæˆæ­£ç¡®æ ¼å¼çš„æ¨ç†ç»“æœ")
    print("="*70)
    
    # åŠ è½½æ¨¡å‹
    model_path = "model/mt5_fast/final"
    print(f"\nğŸ“¦ åŠ è½½æ¨¡å‹: {model_path}")
    
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForSeq2SeqLM.from_pretrained(model_path)
    
    print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    test_file = Path("data/test/Emotion_Summary.jsonl")
    print(f"\nğŸ“Š åŠ è½½æµ‹è¯•æ•°æ®: {test_file}")
    
    test_data = []
    with open(test_file, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                test_data.append(json.loads(line))
    
    print(f"âœ… æµ‹è¯•æ ·æœ¬æ•°: {len(test_data)}")
    
    # è¿›è¡Œæ¨ç†
    print(f"\nğŸ”® å¼€å§‹æ¨ç†...")
    results = []
    
    for item in tqdm(test_data, desc="æ¨ç†è¿›åº¦"):
        # è·å–ID
        item_id = item.get("id", 0)
        
        # æ„é€ ç»“æ„åŒ–prompt
        case_desc = item.get("case_description", [])
        consult_process = item.get("consultation_process", [])
        
        prompt = create_structured_prompt(case_desc, consult_process)
        
        # Tokenize
        inputs = tokenizer(
            prompt,
            max_length=512,  # å¢åŠ é•¿åº¦ä»¥å®¹çº³prompt
            truncation=True,
            padding=False,
            return_tensors="pt"
        )
        
        # ç”Ÿæˆ
        outputs = model.generate(
            **inputs,
            max_length=256,  # ç”Ÿæˆæ›´é•¿çš„è¾“å‡º
            num_beams=4,
            early_stopping=True,
            no_repeat_ngram_size=3,
        )
        
        # è§£ç 
        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        # è§£æä¸º5ä¸ªå­—æ®µ
        parsed_fields = parse_model_output(generated_text)
        
        # æ„å»ºç»“æœ
        result = {
            "id": item_id,
            "predicted_cause": parsed_fields["predicted_cause"],
            "predicted_symptoms": parsed_fields["predicted_symptoms"],
            "predicted_treatment_process": parsed_fields["predicted_treatment_process"],
            "predicted_illness_Characteristics": parsed_fields["predicted_illness_Characteristics"],
            "predicted_treatment_effect": parsed_fields["predicted_treatment_effect"]
        }
        
        results.append(result)
    
    # ä¿å­˜ç»“æœ
    output_file = Path("results/Emotion_Summary_Result.jsonl")
    output_file.parent.mkdir(parents=True, exist_ok=True)
    
    print(f"\nğŸ’¾ ä¿å­˜ç»“æœåˆ°: {output_file}")
    
    with open(output_file, 'w', encoding='utf-8') as f:
        for result in results:
            f.write(json.dumps(result, ensure_ascii=False) + '\n')
    
    print(f"âœ… å®Œæˆï¼å…±ç”Ÿæˆ {len(results)} æ¡ç»“æœ")
    
    # æ˜¾ç¤ºç¤ºä¾‹
    print(f"\nğŸ“ ç¤ºä¾‹è¾“å‡º (å‰3æ¡):")
    print("-"*70)
    for i, result in enumerate(results[:3], 1):
        print(f"\næ ·æœ¬ {i} (ID: {result['id']}):")
        for key in ["predicted_cause", "predicted_symptoms", "predicted_treatment_process", 
                    "predicted_illness_Characteristics", "predicted_treatment_effect"]:
            value = result[key]
            print(f"  {key}: {value[:80]}..." if len(value) > 80 else f"  {key}: {value}")
    
    # éªŒè¯æ ¼å¼
    print(f"\nğŸ” æ ¼å¼éªŒè¯:")
    all_have_fields = all(
        all(key in r for key in ["id", "predicted_cause", "predicted_symptoms", 
                                  "predicted_treatment_process", "predicted_illness_Characteristics", 
                                  "predicted_treatment_effect"])
        for r in results
    )
    
    if all_have_fields:
        print(f"  âœ… æ‰€æœ‰æ ·æœ¬éƒ½åŒ…å«å¿…éœ€å­—æ®µ")
    else:
        print(f"  âŒ éƒ¨åˆ†æ ·æœ¬ç¼ºå°‘å­—æ®µ")
    
    print("\n" + "="*70)
    print("âœ… æ¨ç†å®Œæˆï¼")
    print(f"ğŸ“ æäº¤æ–‡ä»¶: {output_file}")
    print("="*70)

if __name__ == "__main__":
    main()

