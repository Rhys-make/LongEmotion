# -*- coding: utf-8 -*-
"""ç²¾ç¡®æå–è„šæœ¬ - åŸºäºäº”ç»´åº¦æ ¸å¿ƒä¿¡æ¯æç‚¼æŒ‡å—"""

import json
import re
from pathlib import Path
from tqdm import tqdm

def extract_cause_precise(case_desc, consult_process):
    """
    ç—…å› ï¼šæ·±å±‚å¿ƒç†å†²çªã€æœªè§£å†³çš„æƒ…æ„ŸçŸ›ç›¾æˆ–å…³é”®ç°å®äº‹ä»¶
    é‡ç‚¹ï¼šå…³é”®äº‹ä»¶â†’æƒ…æ„Ÿå†²çªâ†’å…³ç³»é˜»ç¢â†’å¿ƒç†è½¬åŒ–
    """
    
    full_text = " ".join(case_desc + consult_process)
    
    # å…³é”®è¯ï¼šæ·±å±‚åŸå› ã€èƒŒæ™¯äº‹ä»¶ã€æƒ…æ„Ÿå†²çª
    cause_patterns = [
        # å®¶åº­èƒŒæ™¯
        r'(adopted|adoption|biological parent|father|mother|family background|childhood|abuse|divorce|death|loss)[^.!?ã€‚ï¼ï¼Ÿ]{0,200}[.!?ã€‚ï¼ï¼Ÿ]',
        # æƒ…æ„Ÿå†²çª
        r'(conflict|guilt|shame|anger|resentment|abandonment|rejection|betray)[^.!?ã€‚ï¼ï¼Ÿ]{0,200}[.!?ã€‚ï¼ï¼Ÿ]',
        # å…³é”®äº‹ä»¶
        r'(after|when|following|since|because of|due to|result from|stem from|trigger)[^.!?ã€‚ï¼ï¼Ÿ]{0,200}[.!?ã€‚ï¼ï¼Ÿ]',
        # å…³ç³»é—®é¢˜
        r'(relationship|marriage|wife|husband|refused|opposed|conflict with)[^.!?ã€‚ï¼ï¼Ÿ]{0,200}[.!?ã€‚ï¼ï¼Ÿ]',
    ]
    
    cause_sentences = []
    for pattern in cause_patterns:
        matches = re.finditer(pattern, full_text, re.IGNORECASE)
        for match in matches:
            sent = match.group(0).strip()
            if len(sent) > 30 and sent not in cause_sentences:
                cause_sentences.append(sent)
    
    # ä¼˜å…ˆé€‰æ‹©åŒ…å«"æ·±å±‚åŸå› "çš„å¥å­
    if cause_sentences:
        # æŒ‰ç›¸å…³æ€§æ’åºï¼ˆåŒ…å«å¤šä¸ªå…³é”®è¯çš„ä¼˜å…ˆï¼‰
        scored = []
        for sent in cause_sentences:
            score = sum([
                2 if any(kw in sent.lower() for kw in ['adopted', 'biological', 'father', 'mother']) else 0,
                2 if any(kw in sent.lower() for kw in ['guilt', 'shame', 'conflict', 'abandonment']) else 0,
                1 if any(kw in sent.lower() for kw in ['because', 'due to', 'result']) else 0,
            ])
            scored.append((score, sent))
        
        scored.sort(reverse=True, key=lambda x: x[0])
        result = " ".join([s[1] for s in scored[:4]])
        
        if len(result) > 600:
            return result[:600].rsplit('.', 1)[0] + "."
        return result
    
    # å¤‡é€‰ï¼šä»å’¨è¯¢è¿‡ç¨‹ä¸­æå–æ¶‰åŠç—…å› åˆ†æçš„éƒ¨åˆ†
    analysis_keywords = ['cause', 'reason', 'origin', 'root', 'stem', 'underlying']
    for text in consult_process:
        if any(kw in text.lower() for kw in analysis_keywords):
            if len(text) > 400:
                return text[:400].rsplit('.', 1)[0] + "."
            return text
    
    # æœ€åå¤‡é€‰
    return " ".join(case_desc)[:400].rsplit('.', 1)[0] + "."

def extract_symptoms_precise(case_desc, consult_process):
    """
    ç—‡çŠ¶ï¼šå…·ä½“çš„èº¯ä½“/å¿ƒç†/è¡Œä¸ºè¡¨ç°
    é‡ç‚¹ï¼šå…·ä½“å¯æ„ŸçŸ¥çš„ç—‡çŠ¶ï¼Œæ’é™¤æ¢å¤è¿‡ç¨‹
    """
    
    full_text = " ".join(case_desc + consult_process)
    
    # ç—‡çŠ¶å…³é”®è¯
    symptom_patterns = [
        # èº¯ä½“ç—‡çŠ¶
        r'(pain|discomfort|dizzy|nausea|throat|chest|stomach|head|sleep)[^.!?ã€‚ï¼ï¼Ÿ]{0,200}[.!?ã€‚ï¼ï¼Ÿ]',
        # å¿ƒç†ç—‡çŠ¶
        r'(anxiety|depress|worry|fear|panic|obsess|compulsive|avoid)[^.!?ã€‚ï¼ï¼Ÿ]{0,200}[.!?ã€‚ï¼ï¼Ÿ]',
        # è¡Œä¸ºç—‡çŠ¶
        r'(check|search|avoid|unable to|difficulty|repeatedly|constantly)[^.!?ã€‚ï¼ï¼Ÿ]{0,200}[.!?ã€‚ï¼ï¼Ÿ]',
        # ç—‡çŠ¶æè¿°
        r'(symptom|experience|feel|suffer|complain)[^.!?ã€‚ï¼ï¼Ÿ]{0,200}[.!?ã€‚ï¼ï¼Ÿ]',
    ]
    
    symptom_sentences = []
    for pattern in symptom_patterns:
        matches = re.finditer(pattern, full_text, re.IGNORECASE)
        for match in matches:
            sent = match.group(0).strip()
            # æ’é™¤"æ¢å¤"ç›¸å…³çš„å¥å­
            if len(sent) > 30 and sent not in symptom_sentences:
                if not any(kw in sent.lower() for kw in ['improved', 'better', 'recovered', 'relief']):
                    symptom_sentences.append(sent)
    
    if symptom_sentences:
        # æŒ‰ç—‡çŠ¶ç›¸å…³æ€§æ’åº
        scored = []
        for sent in symptom_sentences:
            score = sum([
                2 if any(kw in sent.lower() for kw in ['anxiety', 'depression', 'obsessive']) else 0,
                2 if any(kw in sent.lower() for kw in ['pain', 'discomfort', 'throat', 'chest']) else 0,
                1 if any(kw in sent.lower() for kw in ['repeatedly', 'constantly', 'unable']) else 0,
            ])
            scored.append((score, sent))
        
        scored.sort(reverse=True, key=lambda x: x[0])
        result = " ".join([s[1] for s in scored[:5]])
        
        if len(result) > 700:
            return result[:700].rsplit('.', 1)[0] + "."
        return result
    
    # å¤‡é€‰ï¼šä»æ¡ˆä¾‹æè¿°ä¸­æå–
    for text in case_desc:
        if any(kw in text.lower() for kw in ['symptom', 'experience', 'suffer', 'feel']):
            if len(text) > 500:
                return text[:500].rsplit('.', 1)[0] + "."
            return text
    
    return " ".join(case_desc[:2])[:500].rsplit('.', 1)[0] + "."

def extract_treatment_precise(case_desc, consult_process):
    """
    æ²»ç–—è¿‡ç¨‹ï¼šé’ˆå¯¹ç–¾ç—…çš„å¹²é¢„æ­¥éª¤
    é‡ç‚¹ï¼šå…·ä½“æ²»ç–—æ–¹æ³•ï¼Œæ’é™¤é€šç”¨ç†è®º
    """
    
    full_text = " ".join(consult_process)
    
    # æ²»ç–—å…³é”®è¯
    treatment_patterns = [
        # å…·ä½“æ²»ç–—æŠ€æœ¯
        r'(hypnosis|hypnotherapy|cognitive|behavioral|imagery|dialogue|exposure)[^.!?ã€‚ï¼ï¼Ÿ]{0,250}[.!?ã€‚ï¼ï¼Ÿ]',
        # æ²»ç–—è¿‡ç¨‹
        r'(session|consultation|therapy|treatment|intervention|technique)[^.!?ã€‚ï¼ï¼Ÿ]{0,250}[.!?ã€‚ï¼ï¼Ÿ]',
        # å’¨è¯¢å¸ˆè¡Œä¸º
        r'(counselor|therapist|guided|conducted|explored|helped|addressed)[^.!?ã€‚ï¼ï¼Ÿ]{0,250}[.!?ã€‚ï¼ï¼Ÿ]',
        # æ²»ç–—æ­¥éª¤
        r'(first|initially|then|next|following|during|after the)[^.!?ã€‚ï¼ï¼Ÿ]{0,250}[.!?ã€‚ï¼ï¼Ÿ]',
    ]
    
    treatment_sentences = []
    for pattern in treatment_patterns:
        matches = re.finditer(pattern, full_text, re.IGNORECASE)
        for match in matches:
            sent = match.group(0).strip()
            if len(sent) > 30 and sent not in treatment_sentences:
                treatment_sentences.append(sent)
    
    if treatment_sentences:
        # ä¼˜å…ˆåŒ…å«å…·ä½“æŠ€æœ¯çš„å¥å­
        scored = []
        for sent in treatment_sentences:
            score = sum([
                3 if any(kw in sent.lower() for kw in ['hypnosis', 'imagery', 'cognitive', 'behavioral']) else 0,
                2 if any(kw in sent.lower() for kw in ['guided', 'conducted', 'explored']) else 0,
                1 if any(kw in sent.lower() for kw in ['session', 'therapy', 'treatment']) else 0,
            ])
            scored.append((score, sent))
        
        scored.sort(reverse=True, key=lambda x: x[0])
        result = " ".join([s[1] for s in scored[:4]])
        
        if len(result) > 700:
            return result[:700].rsplit('.', 1)[0] + "."
        return result
    
    # å¤‡é€‰ï¼šæå–å’¨è¯¢è¿‡ç¨‹çš„ä¸­é—´éƒ¨åˆ†
    if len(consult_process) > 2:
        middle = " ".join(consult_process[1:3])
        if len(middle) > 600:
            return middle[:600].rsplit('.', 1)[0] + "."
        return middle
    
    return " ".join(consult_process[:2])[:600].rsplit('.', 1)[0] + "."

def extract_characteristics_precise(case_desc, consult_process):
    """
    ç–¾ç—…ç‰¹å¾ï¼šæœ¬è´¨å±æ€§ä¸è¡¨ç°è§„å¾‹
    é‡ç‚¹ï¼šå½’çº³æ€»ç»“ï¼Œæç‚¼è§„å¾‹
    """
    
    full_text = " ".join(case_desc + consult_process)
    
    # ç‰¹å¾å…³é”®è¯
    char_patterns = [
        # ç–¾ç—…æ€§è´¨
        r'(psychological|mental|emotional|disorder|condition|nature)[^.!?ã€‚ï¼ï¼Ÿ]{0,200}[.!?ã€‚ï¼ï¼Ÿ]',
        # è¡¨ç°è§„å¾‹
        r'(pattern|characteristic|feature|tend to|typically|repeatedly)[^.!?ã€‚ï¼ï¼Ÿ]{0,200}[.!?ã€‚ï¼ï¼Ÿ]',
        # ç—‡çŠ¶è§„å¾‹
        r'(when|whenever|fluctuate|variable|depend on|influenced by)[^.!?ã€‚ï¼ï¼Ÿ]{0,200}[.!?ã€‚ï¼ï¼Ÿ]',
        # å¿ƒç†æœºåˆ¶
        r'(defense|mechanism|cope|avoid|anxiety|obsessive|compulsive)[^.!?ã€‚ï¼ï¼Ÿ]{0,200}[.!?ã€‚ï¼ï¼Ÿ]',
    ]
    
    char_sentences = []
    for pattern in char_patterns:
        matches = re.finditer(pattern, full_text, re.IGNORECASE)
        for match in matches:
            sent = match.group(0).strip()
            if len(sent) > 30 and sent not in char_sentences:
                char_sentences.append(sent)
    
    if char_sentences:
        scored = []
        for sent in char_sentences:
            score = sum([
                2 if any(kw in sent.lower() for kw in ['psychological', 'mental', 'disorder']) else 0,
                2 if any(kw in sent.lower() for kw in ['pattern', 'characteristic', 'typically']) else 0,
                1 if any(kw in sent.lower() for kw in ['fluctuate', 'depend', 'influenced']) else 0,
            ])
            scored.append((score, sent))
        
        scored.sort(reverse=True, key=lambda x: x[0])
        result = " ".join([s[1] for s in scored[:4]])
        
        if len(result) > 600:
            return result[:600].rsplit('.', 1)[0] + "."
        return result
    
    # å¤‡é€‰ï¼šä»æ¡ˆä¾‹åˆ†æéƒ¨åˆ†æå–
    for text in consult_process:
        if any(kw in text.lower() for kw in ['analysis', 'characteristic', 'nature', 'disorder']):
            if len(text) > 500:
                return text[:500].rsplit('.', 1)[0] + "."
            return text
    
    return " ".join(case_desc)[:400].rsplit('.', 1)[0] + "."

def extract_effect_precise(case_desc, consult_process):
    """
    æ²»ç–—æ•ˆæœï¼šæ²»ç–—åçš„å…·ä½“æ”¹å–„
    é‡ç‚¹ï¼šå®é™…å˜åŒ–ï¼Œæ’é™¤é¢„æœŸæ•ˆæœ
    """
    
    full_text = " ".join(consult_process)
    
    # æ•ˆæœå…³é”®è¯
    effect_patterns = [
        # æƒ…ç»ªæ”¹å–„
        r'(felt better|relief|improved|happy|smile|calm|peaceful)[^.!?ã€‚ï¼ï¼Ÿ]{0,200}[.!?ã€‚ï¼ï¼Ÿ]',
        # è¡Œä¸ºå˜åŒ–
        r'(no longer|stopped|able to|began to|started to)[^.!?ã€‚ï¼ï¼Ÿ]{0,200}[.!?ã€‚ï¼ï¼Ÿ]',
        # è®¤çŸ¥å˜åŒ–
        r'(realized|understood|recognized|insight|aware)[^.!?ã€‚ï¼ï¼Ÿ]{0,200}[.!?ã€‚ï¼ï¼Ÿ]',
        # æ•ˆæœæè¿°
        r'(after|following|result|outcome|effect|progress)[^.!?ã€‚ï¼ï¼Ÿ]{0,200}[.!?ã€‚ï¼ï¼Ÿ]',
    ]
    
    effect_sentences = []
    
    # ä¼˜å…ˆä»ååŠéƒ¨åˆ†æå–ï¼ˆé€šå¸¸åŒ…å«æ²»ç–—æ•ˆæœï¼‰
    second_half = consult_process[len(consult_process)//2:]
    text_to_search = " ".join(second_half)
    
    for pattern in effect_patterns:
        matches = re.finditer(pattern, text_to_search, re.IGNORECASE)
        for match in matches:
            sent = match.group(0).strip()
            if len(sent) > 30 and sent not in effect_sentences:
                effect_sentences.append(sent)
    
    # å¦‚æœååŠéƒ¨åˆ†æ²¡æ‰¾åˆ°ï¼Œå†æŸ¥æ‰¾å‰åŠéƒ¨åˆ†
    if not effect_sentences:
        for pattern in effect_patterns:
            matches = re.finditer(pattern, full_text, re.IGNORECASE)
            for match in matches:
                sent = match.group(0).strip()
                if len(sent) > 30 and sent not in effect_sentences:
                    effect_sentences.append(sent)
    
    if effect_sentences:
        scored = []
        for sent in effect_sentences:
            score = sum([
                3 if any(kw in sent.lower() for kw in ['relief', 'improved', 'happy', 'smile']) else 0,
                2 if any(kw in sent.lower() for kw in ['no longer', 'able to', 'began']) else 0,
                1 if any(kw in sent.lower() for kw in ['realized', 'understood', 'insight']) else 0,
            ])
            scored.append((score, sent))
        
        scored.sort(reverse=True, key=lambda x: x[0])
        result = " ".join([s[1] for s in scored[:4]])
        
        if len(result) > 600:
            return result[:600].rsplit('.', 1)[0] + "."
        return result
    
    # å¤‡é€‰ï¼šæå–æœ€åéƒ¨åˆ†
    if consult_process:
        last_part = consult_process[-1]
        if len(last_part) > 500:
            return last_part[:500].rsplit('.', 1)[0] + "."
        return last_part
    
    return "The treatment showed positive effects on the client's condition."

def main():
    print("="*80)
    print("ğŸ¯ ç²¾ç¡®æå– - åŸºäºäº”ç»´åº¦æ ¸å¿ƒä¿¡æ¯æç‚¼æŒ‡å—")
    print("="*80)
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    test_file = Path("data/test/Emotion_Summary.jsonl")
    print(f"\nğŸ“Š åŠ è½½æµ‹è¯•æ•°æ®: {test_file}")
    
    test_data = []
    with open(test_file, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                test_data.append(json.loads(line))
    
    print(f"âœ… æµ‹è¯•æ ·æœ¬æ•°: {len(test_data)}")
    
    print(f"\nğŸ’¡ æå–ç­–ç•¥ï¼ˆåŸºäºäº”ç»´åº¦æŒ‡å—ï¼‰:")
    print(f"  1. ç—…å› : æ·±å±‚å¿ƒç†å†²çªã€æƒ…æ„ŸçŸ›ç›¾ã€å…³é”®äº‹ä»¶")
    print(f"  2. ç—‡çŠ¶: å…·ä½“èº¯ä½“/å¿ƒç†/è¡Œä¸ºè¡¨ç°ï¼ˆæ’é™¤æ¢å¤è¿‡ç¨‹ï¼‰")
    print(f"  3. æ²»ç–—è¿‡ç¨‹: å…·ä½“å¹²é¢„æ­¥éª¤ï¼ˆæ’é™¤é€šç”¨ç†è®ºï¼‰")
    print(f"  4. ç–¾ç—…ç‰¹å¾: æœ¬è´¨å±æ€§ä¸è¡¨ç°è§„å¾‹ï¼ˆå½’çº³æ€»ç»“ï¼‰")
    print(f"  5. æ²»ç–—æ•ˆæœ: å®é™…æ”¹å–„ï¼ˆæ’é™¤é¢„æœŸæ•ˆæœï¼‰")
    
    # è¿›è¡Œæå–
    print(f"\nğŸ”® å¼€å§‹ç²¾ç¡®æå–...\n")
    results = []
    
    for item in tqdm(test_data, desc="æå–è¿›åº¦"):
        item_id = item.get("id", 0)
        case_desc = item.get("case_description", [])
        consult_process = item.get("consultation_process", [])
        
        result = {
            "id": item_id,
            "predicted_cause": extract_cause_precise(case_desc, consult_process),
            "predicted_symptoms": extract_symptoms_precise(case_desc, consult_process),
            "predicted_treatment_process": extract_treatment_precise(case_desc, consult_process),
            "predicted_illness_Characteristics": extract_characteristics_precise(case_desc, consult_process),
            "predicted_treatment_effect": extract_effect_precise(case_desc, consult_process)
        }
        
        results.append(result)
    
    # å¤‡ä»½å¹¶ä¿å­˜
    output_file = Path("results/Emotion_Summary_Result.jsonl")
    
    if output_file.exists():
        backup_file = Path("results/Emotion_Summary_Result_v2_rules.jsonl")
        import shutil
        shutil.copy(output_file, backup_file)
        print(f"\nğŸ“¦ æ—§ç‰ˆæœ¬å·²å¤‡ä»½åˆ°: {backup_file}")
    
    print(f"\nğŸ’¾ ä¿å­˜ç»“æœåˆ°: {output_file} (è¦†ç›–)")
    
    with open(output_file, 'w', encoding='utf-8') as f:
        for result in results:
            f.write(json.dumps(result, ensure_ascii=False) + '\n')
    
    print(f"âœ… å®Œæˆï¼å…±ç”Ÿæˆ {len(results)} æ¡ç»“æœ")
    
    # æ˜¾ç¤ºç¤ºä¾‹
    print(f"\nğŸ“ ç¤ºä¾‹è¾“å‡º (æ ·æœ¬ 1 - 34å²ç”·æ€§ç–‘ç—…ç—‡æ¡ˆä¾‹):")
    print("="*80)
    sample = results[0]
    
    fields = [
        ("predicted_cause", "ç—…å› "),
        ("predicted_symptoms", "ç—‡çŠ¶"),
        ("predicted_treatment_process", "æ²»ç–—è¿‡ç¨‹"),
        ("predicted_illness_Characteristics", "ç–¾ç—…ç‰¹å¾"),
        ("predicted_treatment_effect", "æ²»ç–—æ•ˆæœ")
    ]
    
    for field, name in fields:
        content = sample[field]
        print(f"\nã€{name}ã€‘({len(content)} å­—ç¬¦)")
        print(f"{content[:200]}...")
    
    # è´¨é‡æ£€æŸ¥
    print(f"\n" + "="*80)
    print(f"ğŸ” è´¨é‡æ£€æŸ¥")
    print("="*80)
    
    contents = [sample[field] for field, _ in fields]
    unique = len(set(contents))
    print(f"\n1. é‡å¤åº¦: {unique}/5 å”¯ä¸€")
    
    lengths = [len(c) for c in contents]
    print(f"2. å¹³å‡é•¿åº¦: {sum(lengths)/len(lengths):.0f} å­—ç¬¦")
    
    # æ£€æŸ¥å…³é”®è¯è¦†ç›–
    keywords = ["adopt", "hypnosis", "imagery", "anxiety", "relief"]
    full_text = " ".join(contents).lower()
    found = [kw for kw in keywords if kw in full_text]
    print(f"3. å…³é”®è¯è¦†ç›–: {len(found)}/{len(keywords)} ({', '.join(found)})")
    
    print("\n" + "="*80)
    print("âœ… ç²¾ç¡®æå–å®Œæˆï¼")
    print(f"ğŸ“ æäº¤æ–‡ä»¶: {output_file}")
    print("="*80)

if __name__ == "__main__":
    main()

