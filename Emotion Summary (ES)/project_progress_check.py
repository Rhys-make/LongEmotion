# -*- coding: utf-8 -*-
"""æ¯”èµ›ä»»åŠ¡è¿›åº¦å…¨é¢è‡ªæŸ¥"""

import json
from pathlib import Path
from datetime import datetime

print("="*80)
print("ğŸ† æ¯”èµ›ä»»åŠ¡è¿›åº¦å…¨é¢è‡ªæŸ¥")
print(f"æ£€æŸ¥æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print("="*80)

# ========== 1. æ•°æ®å‡†å¤‡æ£€æŸ¥ ==========
print("\n" + "="*80)
print("ğŸ“Š 1. æ•°æ®å‡†å¤‡æ£€æŸ¥")
print("="*80)

train_file = Path("data/train/Emotion_Summary.jsonl")
val_file = Path("data/validation/Emotion_Summary.jsonl")
test_file = Path("data/test/Emotion_Summary.jsonl")

data_status = {}

for name, file_path in [("è®­ç»ƒé›†", train_file), ("éªŒè¯é›†", val_file), ("æµ‹è¯•é›†", test_file)]:
    if file_path.exists():
        with open(file_path, 'r', encoding='utf-8') as f:
            data = [json.loads(line) for line in f if line.strip()]
        
        # æ£€æŸ¥ç¬¬ä¸€æ¡æ•°æ®çš„æ ¼å¼
        sample = data[0] if data else {}
        has_id = "id" in sample
        has_case = "case_description" in sample
        has_consult = "consultation_process" in sample
        has_reflection = "experience_and_reflection" in sample
        
        data_status[name] = {
            "exists": True,
            "count": len(data),
            "format_ok": has_id and has_case and has_consult,
            "has_reflection": has_reflection
        }
        
        print(f"\n{name}:")
        print(f"  âœ… æ–‡ä»¶å­˜åœ¨: {file_path}")
        print(f"  ğŸ“ æ ·æœ¬æ•°é‡: {len(data):,}")
        print(f"  ğŸ” æ ¼å¼æ£€æŸ¥:")
        print(f"     - id: {'âœ…' if has_id else 'âŒ'}")
        print(f"     - case_description: {'âœ…' if has_case else 'âŒ'}")
        print(f"     - consultation_process: {'âœ…' if has_consult else 'âŒ'}")
        print(f"     - experience_and_reflection: {'âœ…' if has_reflection else 'âŒ'}")
    else:
        data_status[name] = {"exists": False}
        print(f"\n{name}: âŒ æ–‡ä»¶ä¸å­˜åœ¨")

# ========== 2. æ¨¡å‹è®­ç»ƒæ£€æŸ¥ ==========
print("\n" + "="*80)
print("ğŸ¤– 2. æ¨¡å‹è®­ç»ƒæ£€æŸ¥")
print("="*80)

model_dir = Path("model/mt5_fast/final")
checkpoint_dir = Path("model/mt5_fast/checkpoint-1000")

training_status = {}

if model_dir.exists():
    required_files = ["config.json", "model.safetensors", "tokenizer.json"]
    missing_files = [f for f in required_files if not (model_dir / f).exists()]
    
    if not missing_files:
        # è¯»å–è®­ç»ƒçŠ¶æ€
        trainer_state = checkpoint_dir / "trainer_state.json"
        if trainer_state.exists():
            with open(trainer_state, 'r', encoding='utf-8') as f:
                state = json.load(f)
            
            log_history = state['log_history']
            train_losses = [log for log in log_history if 'loss' in log]
            
            training_status = {
                "completed": True,
                "steps": state['global_step'],
                "epochs": state['epoch'],
                "initial_loss": train_losses[0]['loss'] if train_losses else None,
                "final_loss": train_losses[-1]['loss'] if train_losses else None,
            }
            
            print(f"\nâœ… æ¨¡å‹è®­ç»ƒå®Œæˆ")
            print(f"  ğŸ“ æ¨¡å‹è·¯å¾„: {model_dir}")
            print(f"  ğŸ“Š è®­ç»ƒçŠ¶æ€:")
            print(f"     - æ€»æ­¥æ•°: {training_status['steps']}")
            print(f"     - è®­ç»ƒè½®æ•°: {training_status['epochs']:.2f}")
            print(f"     - åˆå§‹Loss: {training_status['initial_loss']:.4f}")
            print(f"     - æœ€ç»ˆLoss: {training_status['final_loss']:.4f}")
            print(f"     - Lossæ”¹å–„: {((training_status['initial_loss'] - training_status['final_loss']) / training_status['initial_loss'] * 100):.1f}%")
            
            # æ¨¡å‹å¤§å°
            model_file = model_dir / "model.safetensors"
            size_gb = model_file.stat().st_size / (1024**3)
            print(f"  ğŸ’¾ æ¨¡å‹å¤§å°: {size_gb:.2f} GB")
        else:
            training_status = {"completed": False, "reason": "ç¼ºå°‘è®­ç»ƒçŠ¶æ€æ–‡ä»¶"}
            print(f"\nâš ï¸  æ¨¡å‹å­˜åœ¨ä½†ç¼ºå°‘è®­ç»ƒçŠ¶æ€æ–‡ä»¶")
    else:
        training_status = {"completed": False, "reason": f"ç¼ºå°‘æ–‡ä»¶: {missing_files}"}
        print(f"\nâš ï¸  æ¨¡å‹ä¸å®Œæ•´ï¼Œç¼ºå°‘: {', '.join(missing_files)}")
else:
    training_status = {"completed": False, "reason": "æ¨¡å‹ç›®å½•ä¸å­˜åœ¨"}
    print(f"\nâŒ æ¨¡å‹æœªè®­ç»ƒ")

# ========== 3. æ¨ç†ç»“æœæ£€æŸ¥ ==========
print("\n" + "="*80)
print("ğŸ”® 3. æ¨ç†ç»“æœæ£€æŸ¥")
print("="*80)

results_file = Path("results/test_predictions.jsonl")

inference_status = {}

if results_file.exists():
    with open(results_file, 'r', encoding='utf-8') as f:
        results = [json.loads(line) for line in f if line.strip()]
    
    # æ£€æŸ¥æ ¼å¼
    if results:
        sample = results[0]
        has_all_fields = all(k in sample for k in ["id", "case_description", "consultation_process", "experience_and_reflection"])
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æµ‹è¯•æ ·æœ¬éƒ½æœ‰ç»“æœ
        test_count = data_status.get("æµ‹è¯•é›†", {}).get("count", 0)
        all_processed = len(results) == test_count
        
        # ç»Ÿè®¡ç”Ÿæˆå†…å®¹é•¿åº¦
        gen_lengths = [len(r.get("experience_and_reflection", "")) for r in results]
        avg_length = sum(gen_lengths) / len(gen_lengths) if gen_lengths else 0
        min_length = min(gen_lengths) if gen_lengths else 0
        max_length = max(gen_lengths) if gen_lengths else 0
        
        inference_status = {
            "completed": True,
            "count": len(results),
            "format_ok": has_all_fields,
            "all_processed": all_processed,
            "avg_length": avg_length,
            "min_length": min_length,
            "max_length": max_length
        }
        
        print(f"\nâœ… æ¨ç†å®Œæˆ")
        print(f"  ğŸ“ ç»“æœæ–‡ä»¶: {results_file}")
        print(f"  ğŸ“Š æ¨ç†ç»Ÿè®¡:")
        print(f"     - ç»“æœæ•°é‡: {len(results)}")
        print(f"     - æµ‹è¯•é›†æ•°é‡: {test_count}")
        print(f"     - å®Œæ•´æ€§: {'âœ… å…¨éƒ¨å¤„ç†' if all_processed else 'âŒ ä¸å®Œæ•´'}")
        print(f"     - æ ¼å¼æ­£ç¡®: {'âœ…' if has_all_fields else 'âŒ'}")
        print(f"  ğŸ“ ç”Ÿæˆå†…å®¹é•¿åº¦:")
        print(f"     - å¹³å‡: {avg_length:.0f} å­—ç¬¦")
        print(f"     - æœ€çŸ­: {min_length} å­—ç¬¦")
        print(f"     - æœ€é•¿: {max_length} å­—ç¬¦")
        
        # æ˜¾ç¤ºå‡ ä¸ªç¤ºä¾‹
        print(f"\n  ğŸ“ ç¤ºä¾‹è¾“å‡º (å‰3æ¡):")
        for i, result in enumerate(results[:3], 1):
            gen_text = result.get("experience_and_reflection", "")
            print(f"\n     æ ·æœ¬ {i} (ID: {result.get('id', 'N/A')}):")
            print(f"       ç”Ÿæˆé•¿åº¦: {len(gen_text)} å­—ç¬¦")
            print(f"       å†…å®¹é¢„è§ˆ: {gen_text[:100]}...")
    else:
        inference_status = {"completed": False, "reason": "ç»“æœæ–‡ä»¶ä¸ºç©º"}
        print(f"\nâš ï¸  ç»“æœæ–‡ä»¶å­˜åœ¨ä½†ä¸ºç©º")
else:
    inference_status = {"completed": False, "reason": "ç»“æœæ–‡ä»¶ä¸å­˜åœ¨"}
    print(f"\nâŒ æ¨ç†æœªå®Œæˆ")

# ========== 4. æäº¤æ–‡ä»¶æ£€æŸ¥ ==========
print("\n" + "="*80)
print("ğŸ“¤ 4. æäº¤æ–‡ä»¶æ£€æŸ¥")
print("="*80)

# æ£€æŸ¥ç»“æœæ–‡ä»¶æ˜¯å¦ç¬¦åˆæäº¤æ ¼å¼
submission_ready = False

if results_file.exists() and inference_status.get("completed", False):
    print(f"\nâœ… æäº¤æ–‡ä»¶å·²ç”Ÿæˆ: {results_file}")
    print(f"\n  ğŸ“‹ æäº¤æ–‡ä»¶ä¿¡æ¯:")
    print(f"     - æ–‡ä»¶è·¯å¾„: {results_file}")
    print(f"     - æ–‡ä»¶å¤§å°: {results_file.stat().st_size / 1024:.1f} KB")
    print(f"     - æ ·æœ¬æ•°é‡: {len(results)}")
    
    # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ ·æœ¬éƒ½æœ‰éç©ºçš„ experience_and_reflection
    empty_count = sum(1 for r in results if not r.get("experience_and_reflection", "").strip())
    if empty_count == 0:
        submission_ready = True
        print(f"     - å®Œæ•´æ€§: âœ… æ‰€æœ‰æ ·æœ¬éƒ½æœ‰ç”Ÿæˆå†…å®¹")
    else:
        print(f"     - å®Œæ•´æ€§: âš ï¸  æœ‰ {empty_count} ä¸ªæ ·æœ¬ç¼ºå°‘ç”Ÿæˆå†…å®¹")
else:
    print(f"\nâŒ æäº¤æ–‡ä»¶æœªå‡†å¤‡å¥½")

# ========== 5. æ•´ä½“è¿›åº¦æ€»ç»“ ==========
print("\n" + "="*80)
print("ğŸ“ˆ 5. æ•´ä½“è¿›åº¦æ€»ç»“")
print("="*80)

tasks = [
    ("æ•°æ®å‡†å¤‡", all(s.get("exists", False) for s in data_status.values())),
    ("æ¨¡å‹è®­ç»ƒ", training_status.get("completed", False)),
    ("æµ‹è¯•é›†æ¨ç†", inference_status.get("completed", False)),
    ("æäº¤æ–‡ä»¶å‡†å¤‡", submission_ready),
]

completed_tasks = sum(1 for _, status in tasks if status)
total_tasks = len(tasks)
progress = (completed_tasks / total_tasks) * 100

print(f"\næ•´ä½“è¿›åº¦: {completed_tasks}/{total_tasks} ({progress:.0f}%)")
print(f"\nä»»åŠ¡æ¸…å•:")
for task_name, completed in tasks:
    status = "âœ… å®Œæˆ" if completed else "âŒ æœªå®Œæˆ"
    print(f"  {status} - {task_name}")

# ========== 6. ä¸‹ä¸€æ­¥å»ºè®® ==========
print("\n" + "="*80)
print("ğŸ¯ 6. ä¸‹ä¸€æ­¥æ“ä½œå»ºè®®")
print("="*80)

if progress == 100:
    print("\nğŸ‰ æ­å–œï¼æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼")
    print(f"\nğŸ“¤ å¯ä»¥æäº¤ç»“æœäº†ï¼š")
    print(f"   æ–‡ä»¶è·¯å¾„: {results_file}")
    print(f"   æ ·æœ¬æ•°é‡: {inference_status['count']}")
    print(f"\nğŸ’¡ æäº¤å‰å»ºè®®:")
    print(f"   1. æ£€æŸ¥å‡ ä¸ªæ ·æœ¬çš„ç”Ÿæˆè´¨é‡")
    print(f"   2. ç¡®è®¤æ ¼å¼ç¬¦åˆæ¯”èµ›è¦æ±‚")
    print(f"   3. å¤‡ä»½ç»“æœæ–‡ä»¶")
else:
    print("\nè¿˜éœ€è¦å®Œæˆçš„ä»»åŠ¡:")
    for task_name, completed in tasks:
        if not completed:
            print(f"  âŒ {task_name}")
    
    if not training_status.get("completed", False):
        print(f"\nä¸‹ä¸€æ­¥: å¼€å§‹æ¨¡å‹è®­ç»ƒ")
        print(f"  å‘½ä»¤: python scripts/fast_train.py")
    elif not inference_status.get("completed", False):
        print(f"\nä¸‹ä¸€æ­¥: è¿è¡Œæ¨ç†")
        print(f"  å‘½ä»¤: python scripts/inference_fast.py")

# ========== 7. æ€§èƒ½è¯„ä¼° ==========
print("\n" + "="*80)
print("âš¡ 7. æ€§èƒ½è¯„ä¼°")
print("="*80)

if training_status.get("completed", False) and inference_status.get("completed", False):
    print(f"\næ¨¡å‹æ€§èƒ½:")
    print(f"  è®­ç»ƒLossæ”¹å–„: {((training_status['initial_loss'] - training_status['final_loss']) / training_status['initial_loss'] * 100):.1f}%")
    print(f"  æœ€ç»ˆLoss: {training_status['final_loss']:.4f}")
    
    print(f"\nç”Ÿæˆè´¨é‡æŒ‡æ ‡:")
    print(f"  å¹³å‡ç”Ÿæˆé•¿åº¦: {inference_status['avg_length']:.0f} å­—ç¬¦")
    print(f"  é•¿åº¦èŒƒå›´: {inference_status['min_length']} - {inference_status['max_length']} å­—ç¬¦")
    
    # ç®€å•è´¨é‡è¯„ä¼°
    if inference_status['avg_length'] < 50:
        print(f"  âš ï¸  ç”Ÿæˆå†…å®¹è¾ƒçŸ­ï¼Œå¯èƒ½è´¨é‡ä¸ä½³")
    elif inference_status['avg_length'] > 1000:
        print(f"  âš ï¸  ç”Ÿæˆå†…å®¹è¾ƒé•¿ï¼Œå¯èƒ½åŒ…å«å†—ä½™")
    else:
        print(f"  âœ… ç”Ÿæˆé•¿åº¦åˆç†")

print("\n" + "="*80)
print("âœ… è‡ªæŸ¥å®Œæˆ")
print("="*80)

