# Qwen2-7B-Instruct å¾®è°ƒæŒ‡å—
## Emotion Summary (ES) ä»»åŠ¡

---

## ğŸ“‹ ç›®å½•

1. [æ¨¡å‹é€‰æ‹©ç†ç”±](#æ¨¡å‹é€‰æ‹©ç†ç”±)
2. [ç¯å¢ƒå‡†å¤‡](#ç¯å¢ƒå‡†å¤‡)
3. [æ•°æ®å‡†å¤‡](#æ•°æ®å‡†å¤‡)
4. [å¼€å§‹è®­ç»ƒ](#å¼€å§‹è®­ç»ƒ)
5. [æ¨ç†ä½¿ç”¨](#æ¨ç†ä½¿ç”¨)
6. [å‚æ•°è¯´æ˜](#å‚æ•°è¯´æ˜)

---

## ğŸ¯ æ¨¡å‹é€‰æ‹©ç†ç”±

**Qwen2-7B-Instruct** æ˜¯æœ€é€‚åˆæœ¬é¡¹ç›®çš„æ¨¡å‹ï¼š

### ä¸ºä»€ä¹ˆé€‰æ‹© Qwen2ï¼Ÿ

| ç‰¹æ€§ | è¯´æ˜ |
|------|------|
| âœ… **ä¸­æ–‡ä¼˜åŒ–** | é˜¿é‡Œå·´å·´ä¸“é—¨ä¼˜åŒ–çš„ä¸­æ–‡å¤§æ¨¡å‹ï¼Œä¸­æ–‡ç†è§£èƒ½åŠ›æœ€å¼º |
| âœ… **é•¿æ–‡æœ¬æ”¯æŒ** | æ”¯æŒæœ€é•¿ 32K tokensï¼Œå®Œç¾å¤„ç†é•¿ç¯‡å¿ƒç†å’¨è¯¢æ¡ˆä¾‹ |
| âœ… **PsyQA åŒ¹é…** | ä¸æˆ‘ä»¬ä½¿ç”¨çš„ PsyQA æ•°æ®é›†å®Œç¾åŒ¹é… |
| âœ… **æŒ‡ä»¤éµå¾ª** | Instruct ç‰ˆæœ¬ç»è¿‡æŒ‡ä»¤å¾®è°ƒï¼Œæ›´é€‚åˆä»»åŠ¡å¯¼å‘ |
| âœ… **å¼€æºå‹å¥½** | å®Œå…¨å¼€æºï¼Œå¯å•†ç”¨ï¼Œç¤¾åŒºæ”¯æŒå¥½ |
| âœ… **å‚æ•°é«˜æ•ˆ** | 7B å‚æ•°ï¼Œé…åˆ LoRA å¾®è°ƒï¼Œæ˜¾å­˜å‹å¥½ |

### ä¸å…¶ä»–æ¨¡å‹å¯¹æ¯”

- **vs LLaMA-3.1-8B**: Qwen2 ä¸­æ–‡èƒ½åŠ›æ›´å¼ºï¼Œæ›´é€‚åˆä¸­æ–‡å¿ƒç†å’¨è¯¢
- **vs Mistral-7B**: Qwen2 ä¸“é—¨é’ˆå¯¹ä¸­æ–‡ä¼˜åŒ–ï¼ŒPsyQA æ•ˆæœæ›´å¥½
- **vs Seq2Seqæ¨¡å‹** (T5/BART): å› æœè¯­è¨€æ¨¡å‹æ›´é€‚åˆç”Ÿæˆé•¿æ–‡æœ¬æ‘˜è¦

---

## ğŸ›  ç¯å¢ƒå‡†å¤‡

### 1. ç³»ç»Ÿè¦æ±‚

- **GPU**: æ¨è 16GB+ æ˜¾å­˜ï¼ˆä½¿ç”¨ 4-bit é‡åŒ–æœ€ä½ 12GBï¼‰
- **å†…å­˜**: 16GB+
- **ç£ç›˜**: 50GB+ å¯ç”¨ç©ºé—´
- **ç³»ç»Ÿ**: Windows / Linux / macOS

### 2. å®‰è£…ä¾èµ–

```bash
# è¿›å…¥ ES ç›®å½•
cd "Emotion Summary (ES)"

# å®‰è£… Qwen2 ç›¸å…³ä¾èµ–
pip install -r requirements_qwen2.txt

# æˆ–è€…å®‰è£…å…¨éƒ¨ä¾èµ–
pip install -r requirements_es.txt
```

### 3. éªŒè¯ç¯å¢ƒ

```python
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')"
python -c "import transformers; print(f'Transformers: {transformers.__version__}')"
python -c "import peft; print(f'PEFT: {peft.__version__}')"
```

---

## ğŸ“Š æ•°æ®å‡†å¤‡

æ•°æ®å·²ç»é€šè¿‡ `download_and_convert_psyqa.py` å‡†å¤‡å¥½ï¼š

```
data/
â”œâ”€â”€ train/
â”‚   â””â”€â”€ Emotion_Summary.jsonl      # è®­ç»ƒé›† (85%)
â”œâ”€â”€ validation/
â”‚   â””â”€â”€ Emotion_Summary.jsonl      # éªŒè¯é›† (15%)
â””â”€â”€ test/
    â””â”€â”€ Emotion_Summary.jsonl       # æµ‹è¯•é›†
```

### æ•°æ®æ ¼å¼

```json
{
  "id": 1,
  "case_description": ["æ¡ˆä¾‹æè¿°..."],
  "consultation_process": ["å’¨è¯¢è¿‡ç¨‹1", "å’¨è¯¢è¿‡ç¨‹2", ...],
  "experience_and_reflection": "ç»éªŒä¸åæ€æ€»ç»“..."
}
```

---

## ğŸš€ å¼€å§‹è®­ç»ƒ

### æ–¹å¼ 1: ä½¿ç”¨è„šæœ¬ï¼ˆæ¨èï¼‰

#### Windows:
```bash
cd scripts
start_training_qwen2.bat
```

#### Linux/macOS:
```bash
cd scripts
chmod +x start_training_qwen2.sh
./start_training_qwen2.sh
```

### æ–¹å¼ 2: ç›´æ¥è¿è¡Œ Python

```bash
cd scripts
python train_qwen2.py
```

### æ–¹å¼ 3: è‡ªå®šä¹‰å‚æ•°

```bash
python train_qwen2.py \
    --model_name "Qwen/Qwen2-7B-Instruct" \
    --num_epochs 5 \
    --batch_size 1 \
    --gradient_accumulation_steps 16 \
    --learning_rate 1e-4 \
    --max_length 8192 \
    --lora_r 64
```

---

## ğŸ“ˆ è®­ç»ƒè¿‡ç¨‹

è®­ç»ƒä¼šè‡ªåŠ¨æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š

1. **åŠ è½½æ¨¡å‹** - ä¸‹è½½ Qwen2-7B-Instruct (é¦–æ¬¡è¿è¡Œ)
2. **åº”ç”¨é‡åŒ–** - 4-bit é‡åŒ–èŠ‚çœæ˜¾å­˜
3. **é…ç½® LoRA** - æ·»åŠ  LoRA é€‚é…å™¨å±‚
4. **å‡†å¤‡æ•°æ®** - åŠ è½½è®­ç»ƒå’ŒéªŒè¯æ•°æ®
5. **å¼€å§‹è®­ç»ƒ** - è¿›è¡Œå¾®è°ƒè®­ç»ƒ
6. **ä¿å­˜æ¨¡å‹** - ä¿å­˜ LoRA æƒé‡

### é¢„æœŸæ—¶é—´

- **å•ä¸ª epoch**: ~2-4å°æ—¶ (å–å†³äºGPU)
- **æ€»è®­ç»ƒæ—¶é—´**: ~6-12å°æ—¶ (3 epochs)

### æ˜¾å­˜ä½¿ç”¨

- **4-bit + LoRA**: ~12GB
- **FP16 + LoRA**: ~20GB
- **Full Fine-tuning**: ~40GB+

---

## ğŸ”® æ¨ç†ä½¿ç”¨

è®­ç»ƒå®Œæˆåï¼Œä½¿ç”¨æ¨¡å‹è¿›è¡Œæ¨ç†ï¼š

```python
from model_qwen2 import Qwen2EmotionSummaryModel

# åŠ è½½å¾®è°ƒåçš„æ¨¡å‹
model = Qwen2EmotionSummaryModel(
    model_name="Qwen/Qwen2-7B-Instruct",
    use_lora=True
)

# åŠ è½½ LoRA æƒé‡
model.load_lora_weights("../model/qwen2_emotion_summary/final")

# ç”Ÿæˆæ‘˜è¦
case_desc = ["æ¥è®¿è€…ï¼Œå¥³æ€§ï¼Œ27å²..."]
consult_process = ["å’¨è¯¢è¿‡ç¨‹1", "å’¨è¯¢è¿‡ç¨‹2"]

summary = model.generate_summary(
    case_description=case_desc,
    consultation_process=consult_process
)

print(summary)
```

---

## âš™ï¸ å‚æ•°è¯´æ˜

### æ¨¡å‹å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `model_name` | `Qwen/Qwen2-7B-Instruct` | é¢„è®­ç»ƒæ¨¡å‹åç§° |
| `use_4bit` | `True` | æ˜¯å¦ä½¿ç”¨ 4-bit é‡åŒ– |
| `use_lora` | `True` | æ˜¯å¦ä½¿ç”¨ LoRA å¾®è°ƒ |

### LoRA å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `lora_r` | `64` | LoRA ç§©ï¼ˆè¶Šå¤§è¶Šç²¾ç¡®ï¼Œä½†æ˜¾å­˜å ç”¨æ›´å¤šï¼‰ |
| `lora_alpha` | `16` | LoRA ç¼©æ”¾å› å­ |
| `lora_dropout` | `0.05` | LoRA dropout ç‡ |

### è®­ç»ƒå‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `num_epochs` | `3` | è®­ç»ƒè½®æ•° |
| `batch_size` | `2` | æ¯ä¸ªè®¾å¤‡çš„æ‰¹æ¬¡å¤§å° |
| `gradient_accumulation_steps` | `8` | æ¢¯åº¦ç´¯ç§¯æ­¥æ•° |
| `learning_rate` | `2e-4` | å­¦ä¹ ç‡ |
| `max_length` | `8192` | æœ€å¤§åºåˆ—é•¿åº¦ |

### æœ‰æ•ˆæ‰¹æ¬¡å¤§å°è®¡ç®—

```
æœ‰æ•ˆæ‰¹æ¬¡å¤§å° = batch_size Ã— gradient_accumulation_steps Ã— GPUæ•°é‡
é»˜è®¤: 2 Ã— 8 Ã— 1 = 16
```

---

## ğŸ“ å¸¸è§é—®é¢˜

### Q1: æ˜¾å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ

**æ–¹æ¡ˆ1**: å‡å° `batch_size`
```bash
python train_qwen2.py --batch_size 1
```

**æ–¹æ¡ˆ2**: å¢åŠ  `gradient_accumulation_steps`
```bash
python train_qwen2.py --batch_size 1 --gradient_accumulation_steps 16
```

**æ–¹æ¡ˆ3**: å‡å° `max_length`
```bash
python train_qwen2.py --max_length 4096
```

**æ–¹æ¡ˆ4**: å‡å° `lora_r`
```bash
python train_qwen2.py --lora_r 32
```

### Q2: è®­ç»ƒé€Ÿåº¦æ…¢æ€ä¹ˆåŠï¼Ÿ

1. ç¡®ä¿ä½¿ç”¨ GPU (æ£€æŸ¥ CUDA)
2. ä½¿ç”¨ 4-bit é‡åŒ– (`--use_4bit`)
3. å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ (é»˜è®¤å¼€å¯)
4. è€ƒè™‘ä½¿ç”¨æ›´å°çš„ `max_length`

### Q3: å¦‚ä½•ç»§ç»­è®­ç»ƒï¼Ÿ

```bash
python train_qwen2.py --output_dir ../model/qwen2_emotion_summary
# æ¨¡å‹ä¼šè‡ªåŠ¨ä»æœ€åä¸€ä¸ª checkpoint ç»§ç»­
```

### Q4: å¦‚ä½•è¯„ä¼°æ¨¡å‹ï¼Ÿ

ä½¿ç”¨ `inference.py` è„šæœ¬ï¼š

```bash
python inference.py --model_path ../model/qwen2_emotion_summary/final
```

---

## ğŸ“Š æ€§èƒ½ç›‘æ§

è®­ç»ƒè¿‡ç¨‹ä¸­å¯ä»¥ç›‘æ§ï¼š

1. **Loss æ›²çº¿** - æŸ¥çœ‹ `output_dir/runs/` ä½¿ç”¨ TensorBoard
2. **GPU ä½¿ç”¨ç‡** - ä½¿ç”¨ `nvidia-smi` æˆ– `watch -n 1 nvidia-smi`
3. **è®­ç»ƒæ—¥å¿—** - æŸ¥çœ‹ç»ˆç«¯è¾“å‡º

```bash
# å¯åŠ¨ TensorBoard
tensorboard --logdir=../model/qwen2_emotion_summary/runs
```

---

## ğŸ‰ æ€»ç»“

Qwen2-7B-Instruct + LoRA æ–¹æ¡ˆçš„ä¼˜åŠ¿ï¼š

- âœ… **ä¸­æ–‡æœ€ä¼˜**: ä¸“é—¨ä¼˜åŒ–çš„ä¸­æ–‡æ¨¡å‹
- âœ… **é•¿æ–‡æœ¬**: æ”¯æŒ 32K context
- âœ… **æ˜¾å­˜å‹å¥½**: 4-bit + LoRA ä»…éœ€ 12GB
- âœ… **è®­ç»ƒå¿«é€Ÿ**: LoRA å‚æ•°å°‘ï¼Œæ”¶æ•›å¿«
- âœ… **æ•ˆæœå‡ºè‰²**: PsyQA æ•°æ®é›†è¡¨ç°ä¼˜å¼‚

---

## ğŸ“š ç›¸å…³èµ„æº

- [Qwen2 å®˜æ–¹ä»“åº“](https://github.com/QwenLM/Qwen2)
- [Qwen2 æ¨¡å‹å¡ç‰‡](https://huggingface.co/Qwen/Qwen2-7B-Instruct)
- [PEFT æ–‡æ¡£](https://huggingface.co/docs/peft)
- [LoRA è®ºæ–‡](https://arxiv.org/abs/2106.09685)

---

**ç¥è®­ç»ƒé¡ºåˆ©ï¼** ğŸš€

