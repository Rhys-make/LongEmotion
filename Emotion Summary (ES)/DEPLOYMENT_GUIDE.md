# Qwen2-7B-Instruct å®Œæ•´éƒ¨ç½²æŒ‡å—
## ä»é›¶å¼€å§‹éƒ¨ç½² Emotion Summary æ¨¡å‹

---

## âœ… å·²å®Œæˆçš„å·¥ä½œ

### 1. æ•°æ®å‡†å¤‡ âœ“
- âœ… æˆåŠŸå…‹éš† PsyQA ä»“åº“
- âœ… è½¬æ¢ 100 æ¡ PsyQA ç¤ºä¾‹æ•°æ®ä¸º ES æ ¼å¼
- âœ… æ•°æ®å·²æŒ‰ 85%-15% åˆ†å‰²ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†
- âœ… æ•°æ®ä¿å­˜åœ¨:
  - `data/train/Emotion_Summary.jsonl` (85 samples)
  - `data/validation/Emotion_Summary.jsonl` (15 samples)

### 2. æ¨¡å‹ä»£ç  âœ“
- âœ… åˆ›å»º `model_qwen2.py` - Qwen2 æ¨¡å‹å°è£…
- âœ… åˆ›å»º `train_qwen2.py` - LoRA å¾®è°ƒè®­ç»ƒè„šæœ¬
- âœ… é…ç½®æ–‡ä»¶å·²å‡†å¤‡
- âœ… å¯åŠ¨è„šæœ¬å·²åˆ›å»ºï¼ˆWindows + Linuxï¼‰

### 3. æŠ€æœ¯æ–¹æ¡ˆ âœ“
- âœ… é€‰å®š **Qwen2-7B-Instruct** æ¨¡å‹
- âœ… ä½¿ç”¨ **4-bité‡åŒ–** + **LoRA** é«˜æ•ˆå¾®è°ƒ
- âœ… æ”¯æŒæœ€é•¿ 8K tokens è¾“å…¥ï¼ˆå¯æ‰©å±•åˆ° 32Kï¼‰
- âœ… ä¼˜åŒ–çš„ä¸­æ–‡å¿ƒç†å’¨è¯¢ä»»åŠ¡å¤„ç†

---

## ğŸ“¦ æ­¥éª¤1: å®‰è£…ä¾èµ–

### æ–¹æ³•1: ä½¿ç”¨å›½å†…é•œåƒæºï¼ˆæ¨èï¼‰

```bash
# ä½¿ç”¨æ¸…åé•œåƒæº
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple transformers>=4.37.0
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple peft>=0.7.0
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple accelerate>=0.25.0
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple bitsandbytes>=0.41.0
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple datasets
```

### æ–¹æ³•2: ä½¿ç”¨é˜¿é‡Œäº‘é•œåƒ

```bash
pip install -i https://mirrors.aliyun.com/pypi/simple/ transformers peft accelerate bitsandbytes datasets
```

### æ–¹æ³•3: ä¸€é”®å®‰è£…æ‰€æœ‰ä¾èµ–

```bash
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -r requirements_qwen2.txt
```

### æ ¸å¿ƒä¾èµ–åˆ—è¡¨

| åŒ…å | ç‰ˆæœ¬è¦æ±‚ | ç”¨é€” |
|------|----------|------|
| `torch` | >=2.0.0 | æ·±åº¦å­¦ä¹ æ¡†æ¶ |
| `transformers` | >=4.37.0 | Hugging Face æ¨¡å‹åº“ |
| `peft` | >=0.7.0 | LoRA å¾®è°ƒ |
| `accelerate` | >=0.25.0 | åˆ†å¸ƒå¼è®­ç»ƒ |
| `bitsandbytes` | >=0.41.0 | 4-bit é‡åŒ– |
| `datasets` | latest | æ•°æ®é›†å¤„ç† |

---

## ğŸ”§ æ­¥éª¤2: ç¯å¢ƒéªŒè¯

è¿è¡Œä»¥ä¸‹å‘½ä»¤éªŒè¯ç¯å¢ƒï¼š

```python
# æ£€æŸ¥ CUDA
python -c "import torch; print(f'CUDAå¯ç”¨: {torch.cuda.is_available()}')"
python -c "import torch; print(f'CUDAç‰ˆæœ¬: {torch.version.cuda}')"
python -c "import torch; print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"æ— \"}')"

# æ£€æŸ¥ä¾èµ–
python -c "import transformers; print(f'Transformers: {transformers.__version__}')"
python -c "import peft; print(f'PEFT: {peft.__version__}')"
python -c "import bitsandbytes; print('BitsAndBytes: OK')"
```

### é¢„æœŸè¾“å‡º
```
CUDAå¯ç”¨: True
CUDAç‰ˆæœ¬: 11.8
GPU: NVIDIA GeForce RTX 3090
Transformers: 4.37.2
PEFT: 0.8.0
BitsAndBytes: OK
```

---

## ğŸš€ æ­¥éª¤3: å¼€å§‹è®­ç»ƒ

### é€‰é¡¹A: ä½¿ç”¨å¯åŠ¨è„šæœ¬ï¼ˆæœ€ç®€å•ï¼‰

#### Windows:
```cmd
cd scripts
start_training_qwen2.bat
```

#### Linux/Mac:
```bash
cd scripts
chmod +x start_training_qwen2.sh
./start_training_qwen2.sh
```

### é€‰é¡¹B: Python ç›´æ¥è¿è¡Œ

```bash
cd scripts
python train_qwen2.py
```

### é€‰é¡¹C: è‡ªå®šä¹‰å‚æ•°è¿è¡Œ

```bash
cd scripts

# æ˜¾å­˜è¾ƒå°çš„é…ç½® (12GB)
python train_qwen2.py \
    --batch_size 1 \
    --gradient_accumulation_steps 16 \
    --max_length 4096 \
    --lora_r 32

# æ˜¾å­˜è¾ƒå¤§çš„é…ç½® (24GB+)
python train_qwen2.py \
    --batch_size 2 \
    --gradient_accumulation_steps 8 \
    --max_length 8192 \
    --lora_r 64

# æ›´å¤šè®­ç»ƒè½®æ¬¡
python train_qwen2.py \
    --num_epochs 5 \
    --learning_rate 1e-4
```

---

## â±ï¸ æ­¥éª¤4: ç­‰å¾…è®­ç»ƒå®Œæˆ

### è®­ç»ƒæ—¶é—´ä¼°ç®—

| GPU å‹å· | å• Epoch æ—¶é—´ | 3 Epochs æ€»æ—¶é—´ |
|----------|---------------|-----------------|
| RTX 4090 | ~1-2 å°æ—¶ | 3-6 å°æ—¶ |
| RTX 3090 | ~2-3 å°æ—¶ | 6-9 å°æ—¶ |
| RTX 3080 | ~3-4 å°æ—¶ | 9-12 å°æ—¶ |
| V100 | ~2-3 å°æ—¶ | 6-9 å°æ—¶ |
| A100 | ~1-1.5 å°æ—¶ | 3-4.5 å°æ—¶ |

### ç›‘æ§è®­ç»ƒè¿›åº¦

#### æ–¹æ³•1: æŸ¥çœ‹ç»ˆç«¯è¾“å‡º
è®­ç»ƒè¿‡ç¨‹ä¼šå®æ—¶æ˜¾ç¤º:
- Loss å€¼
- è®­ç»ƒæ­¥æ•°
- é¢„ä¼°å‰©ä½™æ—¶é—´

#### æ–¹æ³•2: ä½¿ç”¨ TensorBoard
```bash
# æ–°å¼€ä¸€ä¸ªç»ˆç«¯
cd "Emotion Summary (ES)"
tensorboard --logdir=model/qwen2_emotion_summary
# è®¿é—® http://localhost:6006
```

#### æ–¹æ³•3: ç›‘æ§ GPU ä½¿ç”¨
```bash
# Linux/Mac
watch -n 1 nvidia-smi

# Windows (PowerShell)
while($true) { nvidia-smi; sleep 1; cls }
```

---

## ğŸ’¾ æ­¥éª¤5: æ¨¡å‹ä¿å­˜ä½ç½®

è®­ç»ƒå®Œæˆåï¼Œæ¨¡å‹ä¼šä¿å­˜åœ¨:

```
model/
â””â”€â”€ qwen2_emotion_summary/
    â”œâ”€â”€ checkpoint-100/      # è®­ç»ƒè¿‡ç¨‹æ£€æŸ¥ç‚¹
    â”œâ”€â”€ checkpoint-200/
    â”œâ”€â”€ ...
    â””â”€â”€ final/               # æœ€ç»ˆæ¨¡å‹ â­
        â”œâ”€â”€ adapter_config.json
        â”œâ”€â”€ adapter_model.bin  # LoRA æƒé‡
        â”œâ”€â”€ tokenizer_config.json
        â””â”€â”€ ...
```

**é‡ç‚¹**: `final/` ç›®å½•åŒ…å«äº†å¾®è°ƒåçš„ LoRA æƒé‡

---

## ğŸ”® æ­¥éª¤6: ä½¿ç”¨æ¨¡å‹æ¨ç†

### ç®€å•æµ‹è¯•

```python
import sys
sys.path.append('scripts')
from model_qwen2 import Qwen2EmotionSummaryModel

# åŠ è½½åŸºç¡€æ¨¡å‹
model = Qwen2EmotionSummaryModel(
    model_name="Qwen/Qwen2-7B-Instruct",
    use_4bit=True,
    use_lora=True
)

# åŠ è½½å¾®è°ƒçš„ LoRA æƒé‡
model.load_lora_weights("../model/qwen2_emotion_summary/final")

# æµ‹è¯•æ•°æ®
case_desc = [
    "æ¥è®¿è€…ï¼Œå¥³æ€§ï¼Œ27å²ï¼Œå…¬å¸èŒå‘˜ã€‚ä¸»è¯‰ï¼šè¿‘3ä¸ªæœˆæƒ…ç»ªä½è½ï¼Œç„¦è™‘ã€‚"
]

consult_process = [
    "æ¥è®¿è€…ä¸»è¯‰: å·¥ä½œå‹åŠ›å¤§ï¼Œå¤±çœ ã€‚",
    "å’¨è¯¢å¸ˆåˆ†æ: è¯†åˆ«è´Ÿé¢æ€ç»´æ¨¡å¼ã€‚",
    "æ²»ç–—æ–¹æ¡ˆ: è®¤çŸ¥è¡Œä¸ºç–—æ³•ã€‚"
]

# ç”Ÿæˆæ‘˜è¦
summary = model.generate_summary(
    case_description=case_desc,
    consultation_process=consult_process
)

print("ç”Ÿæˆçš„ç»éªŒä¸åæ€:")
print(summary)
```

### æ‰¹é‡æ¨ç†

```python
import json
from pathlib import Path

# åŠ è½½æµ‹è¯•æ•°æ®
test_file = Path("../data/test/Emotion_Summary.jsonl")
results = []

with open(test_file, 'r', encoding='utf-8') as f:
    for line in f:
        sample = json.loads(line)
        
        # ç”Ÿæˆæ‘˜è¦
        summary = model.generate_summary(
            case_description=sample['case_description'],
            consultation_process=sample['consultation_process']
        )
        
        # ä¿å­˜ç»“æœ
        result = {
            'id': sample['id'],
            'predicted_summary': summary,
            'reference_summary': sample.get('experience_and_reflection', '')
        }
        results.append(result)

# ä¿å­˜é¢„æµ‹ç»“æœ
with open('../submission/predictions.jsonl', 'w', encoding='utf-8') as f:
    for result in results:
        f.write(json.dumps(result, ensure_ascii=False) + '\n')

print(f"å®Œæˆï¼ç”Ÿæˆäº† {len(results)} ä¸ªé¢„æµ‹")
```

---

## ğŸ“Š æ­¥éª¤7: è¯„ä¼°æ¨¡å‹

### ä½¿ç”¨ ROUGE è¯„ä¼°

```bash
cd scripts
python evaluate.py --model_path ../model/qwen2_emotion_summary/final
```

### æ‰‹åŠ¨è¯„ä¼°

å¯¹æ¯”ç”Ÿæˆçš„æ‘˜è¦å’Œå‚è€ƒæ‘˜è¦ï¼Œè¯„ä¼°:
- âœ… äº‹å®ä¸€è‡´æ€§
- âœ… å®Œæ•´æ€§
- âœ… æµç•…æ€§
- âœ… ä¸“ä¸šæ€§

---

## ğŸ› å¸¸è§é—®é¢˜æ’æŸ¥

### é—®é¢˜1: ä¸‹è½½æ¨¡å‹æ…¢æˆ–å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**: ä½¿ç”¨é•œåƒç«™

```bash
# è®¾ç½® Hugging Face é•œåƒ
export HF_ENDPOINT=https://hf-mirror.com

# Windows PowerShell
$env:HF_ENDPOINT="https://hf-mirror.com"
```

æˆ–æ‰‹åŠ¨ä¸‹è½½:
1. è®¿é—® https://hf-mirror.com/Qwen/Qwen2-7B-Instruct
2. ä¸‹è½½æ‰€æœ‰æ–‡ä»¶åˆ°æœ¬åœ°ç›®å½•
3. ä¿®æ”¹ `model_name` ä¸ºæœ¬åœ°è·¯å¾„

### é—®é¢˜2: CUDA Out of Memory

**è§£å†³æ–¹æ¡ˆ1**: å‡å° batch_size
```bash
python train_qwen2.py --batch_size 1
```

**è§£å†³æ–¹æ¡ˆ2**: å¢åŠ æ¢¯åº¦ç´¯ç§¯
```bash
python train_qwen2.py --gradient_accumulation_steps 16
```

**è§£å†³æ–¹æ¡ˆ3**: å‡å°åºåˆ—é•¿åº¦
```bash
python train_qwen2.py --max_length 4096
```

**è§£å†³æ–¹æ¡ˆ4**: å‡å° LoRA rank
```bash
python train_qwen2.py --lora_r 32
```

### é—®é¢˜3: BitsAndBytes å®‰è£…å¤±è´¥ (Windows)

**åŸå› **: Windows ä¸Š bitsandbytes æ”¯æŒæœ‰é™

**è§£å†³æ–¹æ¡ˆ**:
```bash
# ä½¿ç”¨ CPU ç‰ˆæœ¬æˆ–ä¸ä½¿ç”¨é‡åŒ–
pip install bitsandbytes-windows

# æˆ–è®­ç»ƒæ—¶ä¸ä½¿ç”¨ 4-bit
python train_qwen2.py --use_4bit False  # éœ€è¦æ›´å¤šæ˜¾å­˜
```

### é—®é¢˜4: è®­ç»ƒé€Ÿåº¦æ…¢

**æ£€æŸ¥æ¸…å•**:
- âœ… ç¡®è®¤ä½¿ç”¨ GPU (`nvidia-smi`)
- âœ… ç¡®è®¤ CUDA ç‰ˆæœ¬åŒ¹é… PyTorch
- âœ… ä½¿ç”¨ 4-bit é‡åŒ–
- âœ… å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆé»˜è®¤å¼€å¯ï¼‰
- âœ… ä½¿ç”¨è¾ƒå°çš„ max_length

---

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ•°æ®ä¼˜åŒ–
- ä½¿ç”¨å®Œæ•´ PsyQA æ•°æ®é›†ï¼ˆéœ€è¦ç”³è¯·ï¼‰
- å½“å‰åªæœ‰ 100 ä¸ªç¤ºä¾‹ï¼Œå®Œæ•´æ•°æ®é›†æœ‰ 2W+ æ ·æœ¬

### 2. è®­ç»ƒä¼˜åŒ–
```bash
# æ›´é•¿çš„è®­ç»ƒ
python train_qwen2.py --num_epochs 5

# æ›´å°çš„å­¦ä¹ ç‡ï¼ˆæ›´ç¨³å®šï¼‰
python train_qwen2.py --learning_rate 1e-4

# æ›´å¤§çš„ LoRA rankï¼ˆæ›´é«˜ç²¾åº¦ï¼‰
python train_qwen2.py --lora_r 128
```

### 3. æ¨ç†ä¼˜åŒ–
```python
# è°ƒæ•´ç”Ÿæˆå‚æ•°
summary = model.generate_summary(
    case_description=case_desc,
    consultation_process=consult_process,
    temperature=0.7,      # é™ä½éšæœºæ€§
    top_p=0.9,           # nucleus sampling
    repetition_penalty=1.1  # é¿å…é‡å¤
)
```

---

## ğŸ“š ä¸‹ä¸€æ­¥å»ºè®®

1. **è·å–å®Œæ•´æ•°æ®é›†**
   - è”ç³» PsyQA ä½œè€…è·å–å®Œæ•´æ•°æ®é›†
   - Email: thu-sunhao@foxmail.com

2. **æ‰©å±•è®­ç»ƒæ•°æ®**
   - æ·»åŠ æ›´å¤šå¿ƒç†å’¨è¯¢æ¡ˆä¾‹
   - æ•°æ®å¢å¼ºæŠ€æœ¯

3. **æ¨¡å‹è°ƒä¼˜**
   - å°è¯•ä¸åŒçš„ LoRA å‚æ•°
   - è°ƒæ•´è®­ç»ƒè¶…å‚æ•°
   - ä½¿ç”¨å­¦ä¹ ç‡è°ƒåº¦å™¨

4. **è¯„ä¼°æ”¹è¿›**
   - ä½¿ç”¨å¤šä¸ªè¯„ä¼°æŒ‡æ ‡
   - äººå·¥è¯„ä¼°è´¨é‡
   - A/B æµ‹è¯•

---

## âœ… å®Œæ•´æµç¨‹æ€»ç»“

```bash
# 1. å®‰è£…ä¾èµ–
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -r requirements_qwen2.txt

# 2. éªŒè¯ç¯å¢ƒ
python -c "import torch; print(torch.cuda.is_available())"

# 3. å¼€å§‹è®­ç»ƒ
cd scripts
python train_qwen2.py

# 4. ç­‰å¾…å®Œæˆï¼ˆ6-12å°æ—¶ï¼‰

# 5. ä½¿ç”¨æ¨¡å‹
python inference.py --model_path ../model/qwen2_emotion_summary/final

# 6. ç”Ÿæˆæäº¤æ–‡ä»¶
python generate_submission.py
```

---

## ğŸ‰ æ­å–œï¼

ä½ ç°åœ¨å·²ç»æœ‰äº†ä¸€ä¸ªå®Œæ•´çš„ Qwen2-7B-Instruct æƒ…ç»ªæ€»ç»“æ¨¡å‹ï¼

å¦‚æœ‰ä»»ä½•é—®é¢˜ï¼Œè¯·å‚è€ƒ:
- `QWEN2_TRAINING_GUIDE.md` - è¯¦ç»†è®­ç»ƒæŒ‡å—
- `scripts/model_qwen2.py` - æ¨¡å‹ä»£ç 
- `scripts/train_qwen2.py` - è®­ç»ƒä»£ç 

**ç¥è®­ç»ƒé¡ºåˆ©ï¼** ğŸš€

