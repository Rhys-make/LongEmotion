# LongEmotion æ¯”èµ›æ–¹æ¡ˆ

è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„ LongEmotion æ¯”èµ›è§£å†³æ–¹æ¡ˆï¼Œä½¿ç”¨ FastAPI + Hugging Face Transformers + PyTorch å®ç°äº”ä¸ªæƒ…æ„Ÿä»»åŠ¡ã€‚

## ğŸ“‹ æ¯”èµ›ä»»åŠ¡

1. **Emotion Classification** - æƒ…æ„Ÿåˆ†ç±»
2. **Emotion Detection** - æƒ…æ„Ÿæ£€æµ‹ï¼ˆå¤šæ ‡ç­¾ï¼‰
3. **Emotion Conversation** - æƒ…æ„Ÿå¯¹è¯ç”Ÿæˆ
4. **Emotion Summary** - æƒ…æ„Ÿæ‘˜è¦ç”Ÿæˆ
5. **Emotion QA** - æƒ…æ„Ÿé—®ç­”

## ğŸ—ï¸ é¡¹ç›®ç»“æ„

```
LongEmotion/
â”‚
â”œâ”€â”€ data/                          # æ•°æ®é›†ç¼“å­˜ç›®å½•
â”‚   â”œâ”€â”€ classification/
â”‚   â”œâ”€â”€ detection/
â”‚   â”œâ”€â”€ conversation/
â”‚   â”œâ”€â”€ summary/
â”‚   â””â”€â”€ qa/
â”‚
â”œâ”€â”€ models/                        # æ¨¡å‹å®ç°
â”‚   â”œâ”€â”€ classification_model.py   # åˆ†ç±»æ¨¡å‹
â”‚   â”œâ”€â”€ detection_model.py        # æ£€æµ‹æ¨¡å‹
â”‚   â”œâ”€â”€ conversation_model.py     # å¯¹è¯æ¨¡å‹
â”‚   â”œâ”€â”€ summary_model.py          # æ‘˜è¦æ¨¡å‹
â”‚   â””â”€â”€ qa_model.py               # é—®ç­”æ¨¡å‹
â”‚
â”œâ”€â”€ utils/                         # å·¥å…·æ¨¡å—
â”‚   â”œâ”€â”€ preprocess.py             # æ–‡æœ¬é¢„å¤„ç†
â”‚   â”œâ”€â”€ evaluator.py              # è¯„ä¼°æŒ‡æ ‡
â”‚   â””â”€â”€ trainer.py                # è®­ç»ƒé€»è¾‘
â”‚
â”œâ”€â”€ api/                           # FastAPI æ¥å£
â”‚   â””â”€â”€ main.py                   # API æœåŠ¡å…¥å£
â”‚
â”œâ”€â”€ scripts/                       # è„šæœ¬
â”‚   â”œâ”€â”€ download_dataset.py       # æ•°æ®é›†ä¸‹è½½
â”‚   â”œâ”€â”€ train_all.py              # æ‰¹é‡è®­ç»ƒ
â”‚   â””â”€â”€ inference_all.py          # æ‰¹é‡æ¨ç†
â”‚
â”œâ”€â”€ checkpoints/                   # æ¨¡å‹æ£€æŸ¥ç‚¹ï¼ˆè®­ç»ƒåç”Ÿæˆï¼‰
â”œâ”€â”€ results/                       # æ¨ç†ç»“æœï¼ˆæ¨ç†åç”Ÿæˆï¼‰
â”œâ”€â”€ logs/                          # è®­ç»ƒæ—¥å¿—
â”‚
â”œâ”€â”€ requirements.txt               # ä¾èµ–åŒ…
â””â”€â”€ README.md                     # é¡¹ç›®è¯´æ˜
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

#### åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰

```bash
# ä½¿ç”¨ conda
conda create -n longemotion python=3.10
conda activate longemotion

# æˆ–ä½¿ç”¨ venv
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

#### å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

**ä¸»è¦ä¾èµ–:**
- PyTorch >= 2.0.0
- Transformers >= 4.35.0
- FastAPI >= 0.104.0
- Datasets >= 2.14.0

### 2. ä¸‹è½½æ•°æ®é›†

ä» Hugging Face ä¸‹è½½ LongEmotion æ•°æ®é›†ï¼š

```bash
python scripts/download_dataset.py
```

**å¯é€‰å‚æ•°:**

```bash
# ä¸‹è½½ç‰¹å®šä»»åŠ¡
python scripts/download_dataset.py --tasks classification detection

# æŒ‡å®šç¼“å­˜ç›®å½•
python scripts/download_dataset.py --cache_dir ./data

# åˆ—å‡ºå·²ä¸‹è½½çš„æ•°æ®é›†
python scripts/download_dataset.py --list

# éªŒè¯æ•°æ®é›†å®Œæ•´æ€§
python scripts/download_dataset.py --verify
```

### 3. è®­ç»ƒæ¨¡å‹

#### è®­ç»ƒæ‰€æœ‰ä»»åŠ¡

```bash
python scripts/train_all.py
```

#### è®­ç»ƒç‰¹å®šä»»åŠ¡

```bash
# è®­ç»ƒåˆ†ç±»ä»»åŠ¡
python scripts/train_all.py --tasks classification

# è®­ç»ƒå¤šä¸ªä»»åŠ¡
python scripts/train_all.py --tasks classification detection summary

# è‡ªå®šä¹‰å‚æ•°
python scripts/train_all.py \
    --tasks classification \
    --num_epochs 5 \
    --batch_size 32 \
    --device cuda
```

**è®­ç»ƒå‚æ•°è¯´æ˜:**
- `--data_dir`: æ•°æ®ç›®å½•ï¼ˆé»˜è®¤: `./data`ï¼‰
- `--output_dir`: æ¨¡å‹è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: `./checkpoints`ï¼‰
- `--tasks`: è¦è®­ç»ƒçš„ä»»åŠ¡åˆ—è¡¨
- `--num_epochs`: è®­ç»ƒè½®æ•°ï¼ˆé»˜è®¤: 3ï¼‰
- `--batch_size`: æ‰¹é‡å¤§å°ï¼ˆé»˜è®¤: 16ï¼‰
- `--device`: è®¾å¤‡ï¼ˆ`cuda` æˆ– `cpu`ï¼‰

**è®­ç»ƒç‰¹æ€§:**
- âœ… è‡ªåŠ¨ä¿å­˜æœ€ä½³æ¨¡å‹
- âœ… æ—©åœæœºåˆ¶ï¼ˆ3 è½®ä¸æ”¹è¿›åˆ™åœæ­¢ï¼‰
- âœ… å­¦ä¹ ç‡é¢„çƒ­å’Œè¡°å‡
- âœ… æ¢¯åº¦è£å‰ª
- âœ… è®­ç»ƒå†å²è®°å½•

### 4. ç”Ÿæˆæ¨ç†ç»“æœ

å¯¹æµ‹è¯•é›†è¿›è¡Œæ¨ç†ï¼Œç”Ÿæˆæäº¤æ–‡ä»¶ï¼š

```bash
python scripts/inference_all.py
```

**å¯é€‰å‚æ•°:**

```bash
# æ¨ç†ç‰¹å®šä»»åŠ¡
python scripts/inference_all.py --tasks classification detection

# æŒ‡å®šæ¨¡å‹å’Œæ•°æ®è·¯å¾„
python scripts/inference_all.py \
    --checkpoint_dir ./checkpoints \
    --data_dir ./data \
    --output_dir ./results \
    --device cuda
```

**è¾“å‡ºæ–‡ä»¶:**

æ¨ç†å®Œæˆåï¼Œä¼šåœ¨ `results/` ç›®å½•ç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š
- `classification_test.jsonl`
- `detection_test.jsonl`
- `conversation_test.jsonl`
- `summary_test.jsonl`
- `qa_test.jsonl`

### 5. å¯åŠ¨ API æœåŠ¡

å¯åŠ¨ FastAPI æœåŠ¡ï¼Œæä¾› REST API æ¥å£ï¼š

```bash
cd api
python main.py
```

**å¯é€‰å‚æ•°:**

```bash
python main.py \
    --host 0.0.0.0 \
    --port 8000 \
    --checkpoint_dir ../checkpoints \
    --device cuda \
    --reload  # å¼€å‘æ¨¡å¼è‡ªåŠ¨é‡è½½
```

æœåŠ¡å¯åŠ¨åï¼š
- API æœåŠ¡: http://localhost:8000
- API æ–‡æ¡£: http://localhost:8000/docs
- äº¤äº’å¼æ–‡æ¡£: http://localhost:8000/redoc

## ğŸ”Œ API ä½¿ç”¨ç¤ºä¾‹

### æƒ…æ„Ÿåˆ†ç±»

```python
import requests

response = requests.post(
    "http://localhost:8000/classify",
    json={"text": "ä»Šå¤©å¤©æ°”çœŸå¥½ï¼Œå¿ƒæƒ…ç‰¹åˆ«å¼€å¿ƒï¼"}
)

print(response.json())
# è¾“å‡º:
# {
#     "label": 0,
#     "emotion": "happiness",
#     "confidence": 0.95,
#     "probabilities": {...}
# }
```

### æƒ…æ„Ÿæ£€æµ‹

```python
response = requests.post(
    "http://localhost:8000/detect",
    json={"text": "è¿™éƒ¨ç”µå½±æ—¢è®©äººæ„ŸåŠ¨åˆæœ‰ç‚¹å®³æ€•"}
)

print(response.json())
# è¾“å‡º:
# {
#     "emotions": [
#         {"emotion": "sadness", "score": 0.85},
#         {"emotion": "fear", "score": 0.72}
#     ],
#     "all_scores": {...}
# }
```

### æƒ…æ„Ÿå¯¹è¯

```python
response = requests.post(
    "http://localhost:8000/conversation",
    json={
        "context": "æˆ‘ä»Šå¤©è€ƒè¯•æ²¡è€ƒå¥½ï¼Œæ„Ÿè§‰å¾ˆæ²®ä¸§",
        "emotion": "happiness"  # å¯é€‰ï¼ŒæŒ‡å®šå›å¤çš„æƒ…æ„Ÿ
    }
)

print(response.json())
# è¾“å‡º:
# {
#     "response": "åˆ«ç°å¿ƒï¼å¤±è´¥æ˜¯æˆåŠŸä¹‹æ¯ï¼Œä¸‹æ¬¡ä¸€å®šèƒ½è€ƒå¥½çš„ï¼"
# }
```

### æƒ…æ„Ÿæ‘˜è¦

```python
response = requests.post(
    "http://localhost:8000/summary",
    json={"text": "å¾ˆé•¿çš„æ–‡æœ¬å†…å®¹..."}
)

print(response.json())
# è¾“å‡º:
# {
#     "summary": "ç®€çŸ­çš„æ‘˜è¦å†…å®¹"
# }
```

### æƒ…æ„Ÿé—®ç­”

```python
response = requests.post(
    "http://localhost:8000/qa",
    json={
        "question": "ä¸»äººå…¬çš„æƒ…æ„Ÿæ˜¯ä»€ä¹ˆï¼Ÿ",
        "context": "æ•…äº‹çš„ä¸Šä¸‹æ–‡å†…å®¹..."
    }
)

print(response.json())
# è¾“å‡º:
# {
#     "answer": "å¿«ä¹",
#     "confidence": 0.88
# }
```

## ğŸ§  æ¨¡å‹æ¶æ„

### 1. Emotion Classification
- **åŸºç¡€æ¨¡å‹**: `bert-base-chinese`
- **æ¶æ„**: BERT + åˆ†ç±»å¤´
- **è¾“å‡º**: 7 ç±»æƒ…æ„Ÿæ ‡ç­¾

### 2. Emotion Detection
- **åŸºç¡€æ¨¡å‹**: `bert-base-chinese`
- **æ¶æ„**: BERT + å¤šæ ‡ç­¾åˆ†ç±»å¤´
- **è¾“å‡º**: å¤šä¸ªæƒ…æ„Ÿçš„æ¦‚ç‡åˆ†å¸ƒ

### 3. Emotion Conversation
- **åŸºç¡€æ¨¡å‹**: `Qwen2-1.5B` æˆ– `ChatGLM3-6B`
- **æ¶æ„**: å› æœè¯­è¨€æ¨¡å‹
- **è¾“å‡º**: ç”Ÿæˆå¼å¯¹è¯å›å¤

### 4. Emotion Summary
- **åŸºç¡€æ¨¡å‹**: `google/mt5-base`
- **æ¶æ„**: Encoder-Decoder
- **è¾“å‡º**: æ–‡æœ¬æ‘˜è¦

### 5. Emotion QA
- **åŸºç¡€æ¨¡å‹**: `bert-base-chinese`
- **æ¶æ„**: BERT + QA å¤´ï¼ˆspan extractionï¼‰
- **è¾“å‡º**: ç­”æ¡ˆæ–‡æœ¬åŠä½ç½®

## ğŸ“Š è¯„ä¼°æŒ‡æ ‡

- **Classification**: Accuracy, F1-score, Precision, Recall
- **Detection**: Micro-F1, Macro-F1
- **Conversation**: ROUGE-1, ROUGE-2, ROUGE-L
- **Summary**: ROUGE-1, ROUGE-2, ROUGE-L
- **QA**: Exact Match, ROUGE

## ğŸ’¡ è®­ç»ƒæŠ€å·§

### è¶…å‚æ•°å»ºè®®

| ä»»åŠ¡ | å­¦ä¹ ç‡ | æ‰¹é‡å¤§å° | è®­ç»ƒè½®æ•° | æœ€å¤§é•¿åº¦ |
|-----|--------|---------|---------|---------|
| Classification | 2e-5 | 16-32 | 3-5 | 512 |
| Detection | 2e-5 | 16-32 | 3-5 | 512 |
| Conversation | 5e-5 | 4-8 | 2-3 | 1024 |
| Summary | 5e-5 | 8-16 | 3-5 | 1024 |
| QA | 3e-5 | 8-16 | 2-4 | 512 |

### GPU å†…å­˜ä¼˜åŒ–

å¦‚æœé‡åˆ°æ˜¾å­˜ä¸è¶³ï¼š

```python
# 1. å‡å°æ‰¹é‡å¤§å°
python scripts/train_all.py --batch_size 8

# 2. ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯ï¼ˆä¿®æ”¹ trainer.pyï¼‰
# 3. ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆtorch.cuda.ampï¼‰
# 4. ä½¿ç”¨ 8-bit é‡åŒ–åŠ è½½å¤§æ¨¡å‹
```

### å¯¹è¯å’Œæ‘˜è¦æ¨¡å‹

ç”±äºè¿™ä¸¤ä¸ªä»»åŠ¡éœ€è¦è¾ƒå¤§çš„ç”Ÿæˆå¼æ¨¡å‹ï¼Œå¯ä»¥è€ƒè™‘ï¼š

1. **ä½¿ç”¨å°æ¨¡å‹**: Qwen2-1.5B, mT5-base
2. **LoRA å¾®è°ƒ**: ä»…è®­ç»ƒå°‘é‡å‚æ•°
3. **æç¤ºå·¥ç¨‹**: ä¼˜åŒ–æç¤ºè¯æ¨¡æ¿

## ğŸ”§ å¸¸è§é—®é¢˜

### 1. æ•°æ®é›†ä¸‹è½½å¤±è´¥

```bash
# ä½¿ç”¨é•œåƒç«™ç‚¹
export HF_ENDPOINT=https://hf-mirror.com

# æˆ–æ‰‹åŠ¨ä¸‹è½½åæ”¾åˆ° data/ ç›®å½•
```

### 2. CUDA å†…å­˜ä¸è¶³

- å‡å°æ‰¹é‡å¤§å°
- ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
- ä½¿ç”¨æ¨¡å‹å¹¶è¡Œ

### 3. æ¨¡å‹åŠ è½½é”™è¯¯

ç¡®ä¿æ¨¡å‹è·¯å¾„æ­£ç¡®ï¼š
```bash
ls checkpoints/classification/best_model/
# åº”è¯¥åŒ…å« config.json, pytorch_model.bin ç­‰æ–‡ä»¶
```

### 4. API æœåŠ¡å¯åŠ¨æ…¢

æ¨¡å‹ä¼šåœ¨é¦–æ¬¡è°ƒç”¨æ—¶åŠ è½½ï¼Œå¯ä»¥ï¼š
- é¢„åŠ è½½æ¨¡å‹ï¼ˆä¿®æ”¹ main.pyï¼‰
- ä½¿ç”¨æ¨¡å‹ç¼“å­˜
- å‡å°æ¨¡å‹å¤§å°

## ğŸ“ æäº¤æŒ‡å—

### æ¯”èµ›æäº¤è¦æ±‚

1. **æ¨ç†ç»“æœ**: æ¯ä¸ªä»»åŠ¡çš„ `test.jsonl` æ–‡ä»¶
2. **æ¨¡å‹ä»“åº“**: ä¸Šä¼ æ¨¡å‹åˆ° Hugging Face
3. **ä»£ç ä»“åº“**: ä¸Šä¼ ä»£ç åˆ° GitHub/Hugging Face

### ä¸Šä¼ æ¨¡å‹åˆ° Hugging Face

```python
from huggingface_hub import HfApi

api = HfApi()

# ä¸Šä¼ åˆ†ç±»æ¨¡å‹
api.upload_folder(
    folder_path="./checkpoints/classification/best_model",
    repo_id="your-username/longemotion-classification",
    repo_type="model"
)
```

### æäº¤æ–‡ä»¶æ ¼å¼

æ¯ä¸ª `test.jsonl` æ–‡ä»¶æ ¼å¼ç¤ºä¾‹ï¼š

```jsonl
{"text": "...", "label": 0, "emotion": "happiness", ...}
{"text": "...", "label": 1, "emotion": "sadness", ...}
```

## ğŸ”¬ æ‰©å±•ä¸æ”¹è¿›

### å¯èƒ½çš„æ”¹è¿›æ–¹å‘

1. **æ•°æ®å¢å¼º**: å›è¯‘ã€åŒä¹‰è¯æ›¿æ¢
2. **æ¨¡å‹é›†æˆ**: å¤šæ¨¡å‹æŠ•ç¥¨æˆ–èåˆ
3. **å¯¹æŠ—è®­ç»ƒ**: æé«˜æ¨¡å‹é²æ£’æ€§
4. **å¤šä»»åŠ¡å­¦ä¹ **: å…±äº«ç¼–ç å™¨
5. **Prompt å·¥ç¨‹**: ä¼˜åŒ–ç”Ÿæˆå¼ä»»åŠ¡çš„æç¤º

### æ·»åŠ æ–°ä»»åŠ¡

1. åœ¨ `models/` ä¸‹åˆ›å»ºæ–°æ¨¡å‹ç±»
2. åœ¨ `scripts/train_all.py` æ·»åŠ è®­ç»ƒé€»è¾‘
3. åœ¨ `scripts/inference_all.py` æ·»åŠ æ¨ç†é€»è¾‘
4. åœ¨ `api/main.py` æ·»åŠ  API è·¯ç”±

## ğŸ“š å‚è€ƒèµ„æº

- **Hugging Face Transformers**: https://huggingface.co/docs/transformers
- **FastAPI æ–‡æ¡£**: https://fastapi.tiangolo.com
- **PyTorch æ–‡æ¡£**: https://pytorch.org/docs
- **LongEmotion æ•°æ®é›†**: https://huggingface.co/datasets/LongEmotion/LongEmotion

## ğŸ“„ è®¸å¯è¯

MIT License

## ğŸ‘¥ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ“§ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æäº¤ Issue æˆ–è”ç³»é¡¹ç›®ç»´æŠ¤è€…ã€‚

---

**ç¥ä½ åœ¨ LongEmotion æ¯”èµ›ä¸­å–å¾—å¥½æˆç»©ï¼** ğŸ†
