"""
ä¸ºæµ‹è¯•é›†ç”Ÿæˆ Counselor å›å¤
"""
import argparse
import json
import sys
from pathlib import Path
from typing import List, Dict
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(Path(__file__).parent.parent))

from conversation.src.factory import CounselorFactory


def parse_conversation_history(conversation_history: str) -> List[Dict]:
    """
    è§£æå¯¹è¯å†å²å­—ç¬¦ä¸²
    
    Args:
        conversation_history: å¯¹è¯å†å²å­—ç¬¦ä¸²
        
    Returns:
        è§£æåçš„å¯¹è¯åˆ—è¡¨
    """
    if not conversation_history or not isinstance(conversation_history, str):
        return []
    
    # å°è¯•è§£æ JSON æ ¼å¼
    try:
        parsed = json.loads(conversation_history)
        if isinstance(parsed, list):
            return parsed
        elif isinstance(parsed, dict):
            messages = []
            for key, value in parsed.items():
                if isinstance(value, str):
                    messages.append({"role": "client", "message": value})
            return messages
    except:
        pass
    
    # å¦‚æœä¸æ˜¯ JSONï¼Œå°è¯•æŒ‰è¡Œåˆ†å‰²
    lines = conversation_history.split('\n')
    messages = []
    current_role = "client"
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        # å°è¯•è¯†åˆ«è§’è‰²
        if line.startswith("å®¢æˆ·:") or line.startswith("Client:") or line.startswith("ç”¨æˆ·:"):
            current_role = "client"
            message = line.split(":", 1)[1].strip() if ":" in line else line
        elif line.startswith("å’¨è¯¢å¸ˆ:") or line.startswith("Counselor:") or line.startswith("åŠ©æ‰‹:"):
            current_role = "counselor"
            message = line.split(":", 1)[1].strip() if ":" in line else line
        else:
            message = line
        
        if message:
            messages.append({
                "role": current_role,
                "message": message
            })
    
    return messages


def extract_context_from_history(conversation_history: List[Dict]) -> Dict:
    """
    ä»å¯¹è¯å†å²ä¸­æå–ä¸Šä¸‹æ–‡
    
    Args:
        conversation_history: å¯¹è¯å†å²åˆ—è¡¨
        
    Returns:
        åŒ…å« client_information, reason_counseling, cbt_plan çš„å­—å…¸
    """
    if not conversation_history:
        return {
            "client_information": "",
            "reason_counseling": "",
            "cbt_plan": "åŸºäºè®¤çŸ¥è¡Œä¸ºç†è®ºï¼Œå¸®åŠ©å®¢æˆ·è¯†åˆ«å’Œæ”¹å˜è´Ÿé¢æ€ç»´æ¨¡å¼ï¼Œå»ºç«‹ç§¯æçš„åº”å¯¹ç­–ç•¥"
        }
    
    # æå–ç¬¬ä¸€æ¡å®¢æˆ·æ¶ˆæ¯ä½œä¸ºå’¨è¯¢åŸå› 
    first_client_message = ""
    for msg in conversation_history:
        if msg.get('role') == 'client':
            first_client_message = msg.get('message', '')
            break
    
    client_information = f"å¯¹è¯åŒ…å« {len(conversation_history)} æ¡æ¶ˆæ¯"
    
    return {
        "client_information": client_information,
        "reason_counseling": first_client_message[:500] if first_client_message else "éœ€è¦æƒ…æ„Ÿæ”¯æŒå’Œå’¨è¯¢",
        "cbt_plan": "åŸºäºè®¤çŸ¥è¡Œä¸ºç†è®ºï¼Œå¸®åŠ©å®¢æˆ·è¯†åˆ«å’Œæ”¹å˜è´Ÿé¢æ€ç»´æ¨¡å¼ï¼Œå»ºç«‹ç§¯æçš„åº”å¯¹ç­–ç•¥"
    }


def generate_response_for_item(
    item: Dict,
    counselor,
    item_id: int
) -> Dict:
    """
    ä¸ºå•ä¸ªæµ‹è¯•é¡¹ç”Ÿæˆ Counselor å›å¤
    
    Args:
        item: æµ‹è¯•é¡¹
        counselor: å’¨è¯¢å¸ˆä»£ç†
        item_id: é¡¹ç›®ID
        
    Returns:
        åŒ…å« id å’Œ predicted_response çš„å­—å…¸
    """
    conversation_history_str = item.get('conversation_history', '')
    
    # è§£æå¯¹è¯å†å²
    conversation_history = parse_conversation_history(conversation_history_str)
    
    # æå–ä¸Šä¸‹æ–‡
    context = extract_context_from_history(conversation_history)
    
    # æ‰¾åˆ°æœ€åä¸€ä¸ªå®¢æˆ·æ¶ˆæ¯ï¼ˆéœ€è¦å›å¤çš„ï¼‰
    last_client_idx = -1
    for i in range(len(conversation_history) - 1, -1, -1):
        if conversation_history[i].get('role') == 'client':
            last_client_idx = i
            break
    
    # æ„å»ºç”¨äºç”Ÿæˆçš„å†å²ï¼ˆåˆ°æœ€åä¸€ä¸ªå®¢æˆ·æ¶ˆæ¯ä¸ºæ­¢ï¼‰
    if last_client_idx >= 0:
        history_for_generation = conversation_history[:last_client_idx + 1]
    else:
        # å¦‚æœæ²¡æœ‰å®¢æˆ·æ¶ˆæ¯ï¼Œä½¿ç”¨å…¨éƒ¨å†å²
        history_for_generation = conversation_history
    
    # ç”Ÿæˆ Counselor å›å¤
    try:
        counselor_response = counselor.generate(
            history=history_for_generation,
            client_information=context['client_information'],
            reason_counseling=context['reason_counseling'],
            cbt_plan=context['cbt_plan']
        )
    except Exception as e:
        print(f"ç”Ÿæˆå›å¤æ—¶å‡ºé”™ (ID: {item_id}): {e}")
        counselor_response = "[ç”Ÿæˆå¤±è´¥]"
    
    return {
        "id": item_id,
        "predicted_response": counselor_response
    }


def main():
    parser = argparse.ArgumentParser(description="ä¸ºæµ‹è¯•é›†ç”Ÿæˆ Counselor å›å¤")
    parser.add_argument(
        "--input_file",
        type=str,
        default="conversation/data/longemotion_emotion_conversation.json",
        help="è¾“å…¥æµ‹è¯•é›†æ–‡ä»¶"
    )
    parser.add_argument(
        "--output_file",
        type=str,
        default="conversation/output/predicted_responses.json",
        help="è¾“å‡ºæ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--counselor_type",
        type=str,
        default="cactus",
        help="å’¨è¯¢å¸ˆç±»å‹"
    )
    parser.add_argument(
        "--llm_type",
        type=str,
        default="cbt",
        help="LLMç±»å‹ï¼ˆchatgpt, llama2, llama3, longemotion, cbtï¼‰"
    )
    parser.add_argument(
        "--max_samples",
        type=int,
        default=None,
        help="æœ€å¤§å¤„ç†æ ·æœ¬æ•°ï¼ˆNoneè¡¨ç¤ºå…¨éƒ¨ï¼‰"
    )
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("ç”Ÿæˆ Counselor å›å¤")
    print("=" * 60)
    print(f"è¾“å…¥æ–‡ä»¶: {args.input_file}")
    print(f"è¾“å‡ºæ–‡ä»¶: {args.output_file}")
    print(f"å’¨è¯¢å¸ˆç±»å‹: {args.counselor_type}")
    print(f"LLMç±»å‹: {args.llm_type}")
    print("=" * 60)
    
    # åŠ è½½æµ‹è¯•é›†
    print("\næ­£åœ¨åŠ è½½æµ‹è¯•é›†...")
    with open(args.input_file, 'r', encoding='utf-8') as f:
        testset = json.load(f)
    
    print(f"âœ… æµ‹è¯•é›†åŠ è½½æˆåŠŸï¼Œå…± {len(testset)} æ¡è®°å½•")
    
    # é™åˆ¶æ ·æœ¬æ•°
    if args.max_samples:
        testset = testset[:args.max_samples]
        print(f"é™åˆ¶ä¸ºå‰ {len(testset)} æ¡è®°å½•")
    
    # åˆ›å»ºå’¨è¯¢å¸ˆä»£ç†
    print(f"\næ­£åœ¨åˆå§‹åŒ–å’¨è¯¢å¸ˆä»£ç†...")
    try:
        counselor = CounselorFactory.get_counselor(args.counselor_type, args.llm_type)
        print(f"âœ… å’¨è¯¢å¸ˆä»£ç†åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ å’¨è¯¢å¸ˆä»£ç†åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # ç”Ÿæˆå›å¤
    print(f"\nå¼€å§‹ç”Ÿæˆ Counselor å›å¤...")
    results = []
    
    for item in tqdm(testset, desc="å¤„ç†ä¸­"):
        item_id = item.get('id', len(results))
        result = generate_response_for_item(item, counselor, item_id)
        results.append(result)
    
    # ä¿å­˜ç»“æœ
    output_path = Path(args.output_file)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    # åŒæ—¶è¾“å‡ºä¸ºæŒ‡å®šæ ¼å¼ï¼ˆæ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡ï¼‰
    output_txt = output_path.with_suffix('.txt')
    with open(output_txt, 'w', encoding='utf-8') as f:
        for result in results:
            json_line = json.dumps(result, ensure_ascii=False)
            f.write(json_line + '\n')
    
    print(f"\nâœ… å®Œæˆï¼å…±å¤„ç† {len(results)} æ¡è®°å½•")
    print(f"ğŸ“ JSONæ ¼å¼: {output_path}")
    print(f"ğŸ“ æ–‡æœ¬æ ¼å¼: {output_txt}")
    
    # æ˜¾ç¤ºå‰3æ¡ç»“æœ
    print("\nå‰3æ¡ç»“æœé¢„è§ˆ:")
    for i, result in enumerate(results[:3]):
        print(f"\n{json.dumps(result, ensure_ascii=False)}")


if __name__ == "__main__":
    main()

