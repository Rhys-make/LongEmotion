# Cactus: åŸºäºè®¤çŸ¥è¡Œä¸ºç†è®ºçš„å¿ƒç†å­¦å’¨è¯¢å¯¹è¯ç³»ç»Ÿ

è¿™æ˜¯ Cactus é¡¹ç›®çš„å®ç°ï¼ŒåŸºäºè®¤çŸ¥è¡Œä¸ºç†è®ºï¼ˆCognitive Behavioral Theory, CBTï¼‰çš„å¿ƒç†å­¦å’¨è¯¢å¯¹è¯ç³»ç»Ÿã€‚

## ğŸ“Œ æ•°æ®é›†å’Œæ¨¡å‹

æœ¬é¡¹ç›®é›†æˆäº† Hugging Face ä¸Šçš„æ•°æ®é›†å’Œæ¨¡å‹ï¼š

- **æ•°æ®é›†**: [LangAGI-Lab/cactus](https://huggingface.co/datasets/LangAGI-Lab/cactus)
- **æ¨¡å‹**: [LangAGI-Lab/camel](https://huggingface.co/LangAGI-Lab/camel)
- **CBT æ¨¡å‹**: [help2opensource/Qwen3-4B-Instruct-2507_mental_health_cbt](https://huggingface.co/help2opensource/Qwen3-4B-Instruct-2507_mental_health_cbt)
- **Collection**: [Cactus Collection](https://huggingface.co/collections/LangAGI-Lab/cactus-towards-psychological-counseling-conversations)

### ä¸‹è½½ CBT æ¨¡å‹

é¦–å…ˆéœ€è¦ä¸‹è½½ CBT å¿ƒç†å¥åº·æ¨¡å‹åˆ°æœ¬åœ°ï¼š

```bash
python scripts/download_model.py \
    --model_name help2opensource/Qwen3-4B-Instruct-2507_mental_health_cbt \
    --output_dir conversation/model
```

æ¨¡å‹å°†ä¸‹è½½åˆ° `conversation/model/` ç›®å½•ã€‚

### åŠ è½½æ•°æ®é›†

```bash
python scripts/load_longemotion_dataset.py \
    --output_file data/longemotion_test.json \
    --max_samples 100 \
    --split test
```

### ä½¿ç”¨æ¨¡å‹

#### ä½¿ç”¨ CBT æ¨¡å‹ï¼ˆæ¨èï¼‰

```bash
python scripts/inference.py \
    --input_file data/longemotion_testset.json \
    --output_dir output \
    --counselor_type cactus \
    --llm_type cbt \
    --max_turns 20
```

#### ä½¿ç”¨ LongEmotion æ¨¡å‹

```bash
python scripts/inference.py \
    --input_file data/longemotion_test.json \
    --output_dir output \
    --counselor_type cactus \
    --llm_type longemotion \
    --max_turns 20
```

## é¡¹ç›®ç»“æ„

```
conversation/
â”œâ”€â”€ prompts/                  # æç¤ºæ¨¡æ¿æ–‡ä»¶
â”‚   â”œâ”€â”€ agent_cactus_chatgpt.txt
â”‚   â”œâ”€â”€ agent_cactus_llama2.txt
â”‚   â”œâ”€â”€ agent_cactus_llama3.txt
â”‚   â””â”€â”€ agent_cactus_longemotion.txt
â”œâ”€â”€ model/                    # æœ¬åœ°æ¨¡å‹ç›®å½•ï¼ˆä¸‹è½½çš„ CBT æ¨¡å‹ï¼‰
â”œâ”€â”€ src/                      # æºä»£ç 
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py            # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ llm.py               # LLMå®ç°
â”‚   â”œâ”€â”€ agent.py             # å’¨è¯¢å¸ˆä»£ç†
â”‚   â”œâ”€â”€ factory.py           # å·¥å‚ç±»
â”‚   â”œâ”€â”€ longemotion_dataset.py    # LongEmotionæ•°æ®é›†åŠ è½½å™¨
â”‚   â”œâ”€â”€ longemotion_model.py      # LongEmotionæ¨¡å‹åŠ è½½å™¨
â”‚   â””â”€â”€ cbt_model.py         # CBTæ¨¡å‹åŠ è½½å™¨
â”œâ”€â”€ scripts/                  # è„šæœ¬æ–‡ä»¶
â”‚   â”œâ”€â”€ inference.py         # æ¨ç†è„šæœ¬
â”‚   â”œâ”€â”€ inference.sh         # æ¨ç†è„šæœ¬ï¼ˆShellï¼‰
â”‚   â”œâ”€â”€ download_model.py    # ä¸‹è½½ CBT æ¨¡å‹
â”‚   â”œâ”€â”€ download_testset.py  # ä¸‹è½½æµ‹è¯•é›†
â”‚   â”œâ”€â”€ load_longemotion_dataset.py # åŠ è½½æ•°æ®é›†
â”‚   â””â”€â”€ run_vllm.sh          # vLLMæœåŠ¡å™¨å¯åŠ¨è„šæœ¬
â”œâ”€â”€ conf.d/                   # é…ç½®æ–‡ä»¶ç›®å½•
â”‚   â””â”€â”€ config.yaml.example   # é…ç½®ç¤ºä¾‹
â”œâ”€â”€ requirements.txt          # ä¾èµ–åŒ…
â””â”€â”€ README.md                 # æœ¬æ–‡ä»¶
```

## å®‰è£…

### 1. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

æ¨èä½¿ç”¨ `conda` æˆ– `virtualenv`ï¼š

#### ä½¿ç”¨ Conda

```bash
conda create -n cactus python=3.8
conda activate cactus
```

#### ä½¿ç”¨ Virtualenv

```bash
# å¦‚æœæœªå®‰è£…virtualenv
pip install virtualenv

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
virtualenv .venv
source .venv/bin/activate  # Linux & macOS
.venv\Scripts\activate     # Windows
```

### 2. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### 3. é…ç½®æ–‡ä»¶

å¤åˆ¶é…ç½®æ–‡ä»¶ç¤ºä¾‹å¹¶å¡«å†™ï¼š

```bash
cp conf.d/config.yaml.example conf.d/config.yaml
```

ç¼–è¾‘ `conf.d/config.yaml`ï¼š

```yaml
openai:
  key: <<Your openai API key>>

llama2:
  host: http://<<Server IP or URL>>/v1

llama3:
  host: http://<<Server IP or URL>>/v1
```

## ä½¿ç”¨æ–¹æ³•

### 1. å‡†å¤‡è¾“å…¥æ•°æ®

åˆ›å»ºJSONæ ¼å¼çš„å®¢æˆ·ä¿¡æ¯è¡¨ï¼ˆintake formï¼‰ï¼š

```json
{
  "id": 1,
  "client_information": "25å²å¥³æ€§ï¼Œå·¥ä½œå‹åŠ›å¤§",
  "reason_counseling": "æœ€è¿‘æ„Ÿåˆ°ç„¦è™‘ï¼Œéš¾ä»¥å…¥ç¡",
  "cbt_plan": "å¸®åŠ©å®¢æˆ·è¯†åˆ«ç„¦è™‘çš„è§¦å‘å› ç´ ï¼Œå»ºç«‹åº”å¯¹ç­–ç•¥"
}
```

æˆ–æ•°ç»„æ ¼å¼ï¼š

```json
[
  {
    "id": 1,
    "client_information": "...",
    "reason_counseling": "...",
    "cbt_plan": "..."
  }
]
```

### 2. ä¸‹è½½æµ‹è¯•é›†ï¼ˆå¯é€‰ï¼‰

å¦‚æœè¦ä½¿ç”¨ LongEmotion æµ‹è¯•é›†ï¼š

```bash
# ä» Hugging Face ä¸‹è½½ emotion_conversation æµ‹è¯•é›†
python scripts/download_testset.py \
    --output_file data/longemotion_testset.json \
    --split default \
    --max_samples 100
```

è¿™ä¼šä¸‹è½½ [LongEmotion/LongEmotion](https://huggingface.co/datasets/LongEmotion/LongEmotion/viewer/default/emotion_conversation) æ•°æ®é›†çš„ `emotion_conversation` å­é›†ä½œä¸ºæµ‹è¯•é›†ã€‚

### 3. è¿è¡Œæ¨ç†

#### ä½¿ç”¨Pythonè„šæœ¬

```bash
# ä½¿ç”¨è‡ªå®šä¹‰æ•°æ® + ChatGPT
python scripts/inference.py \
    --input_file ./data/intake_forms.json \
    --output_dir ./output \
    --counselor_type cactus \
    --llm_type chatgpt \
    --max_turns 20

# ä½¿ç”¨ LongEmotion æµ‹è¯•é›† + LongEmotion æ¨¡å‹
python scripts/inference.py \
    --input_file ./data/longemotion_testset.json \
    --output_dir ./output \
    --counselor_type cactus \
    --llm_type longemotion \
    --max_turns 20
```

#### ä½¿ç”¨Shellè„šæœ¬

```bash
sh scripts/inference.sh \
    --input_file ./data/intake_forms.json \
    --output_dir ./output \
    --counselor_type cactus \
    --llm_type chatgpt \
    --max_turns 20
```

### 3. è¿è¡ŒvLLMæœåŠ¡å™¨ï¼ˆå¯é€‰ï¼‰

å¦‚æœéœ€è¦ä½¿ç”¨Llama2æˆ–Llama3æ¨¡å‹ï¼Œéœ€è¦å…ˆå¯åŠ¨vLLMæœåŠ¡å™¨ï¼š

```bash
sh scripts/run_vllm.sh \
    --model meta-llama/Llama-2-7b-chat-hf \
    --host 0.0.0.0 \
    --port 8000
```

ç„¶ååœ¨ `config.yaml` ä¸­é…ç½®å¯¹åº”çš„hostã€‚

## æ·»åŠ æ–°çš„å’¨è¯¢å¸ˆä»£ç†

### 1. åˆ›å»ºæç¤ºæ–‡ä»¶

åœ¨ `prompts` ç›®å½•ä¸‹åˆ›å»ºæ–‡ä»¶ï¼Œå‘½åæ ¼å¼ï¼š`agent_{counselor_type}_{llm_type}.txt`

ä¾‹å¦‚ï¼š`agent_new_counselor_chatgpt.txt`

æç¤ºæ–‡ä»¶åº”åŒ…å«ä»¥ä¸‹å˜é‡ï¼š
- `{client_information}` - å®¢æˆ·ä¿¡æ¯
- `{reason_counseling}` - å’¨è¯¢åŸå› 
- `{cbt_plan}` - CBTè®¡åˆ’
- `{history}` - å¯¹è¯å†å²

### 2. åˆ›å»ºå’¨è¯¢å¸ˆä»£ç†ç±»

åœ¨ `src/agent.py` ä¸­æ·»åŠ æ–°ç±»ï¼š

```python
class NewCounselorAgent(CounselorAgent):
    def __init__(self, llm_type):
        super().__init__(llm_type)
        self.language = "english"  # æˆ– "chinese"
        prompt_text = self.load_prompt(f"agent_new_{llm_type}.txt")
        self.prompt_template = PromptTemplate(
            input_variables=["client_information", "reason_counseling", "cbt_plan", "history"],
            template=prompt_text
        )
    
    def generate(self, history, client_information="", reason_counseling="", cbt_plan=""):
        formatted_history = self.format_history(history)
        prompt = self.prompt_template.format(
            client_information=client_information,
            reason_counseling=reason_counseling,
            cbt_plan=cbt_plan,
            history=formatted_history
        )
        return self.llm.generate(prompt)
```

### 3. æ·»åŠ åˆ°å·¥å‚ç±»

åœ¨ `src/factory.py` çš„ `CounselorFactory` ä¸­æ·»åŠ ï¼š

```python
if counselor_type == "new":
    return NewCounselorAgent(llm_type)
```

## æ·»åŠ æ–°çš„LLM

### 1. åˆ›å»ºLLMç±»

åœ¨ `src/llm.py` ä¸­æ·»åŠ ï¼š

```python
class NewLLM(LLM):
    def __init__(self):
        config = get_config()
        # ä»é…ç½®ä¸­è¯»å–å‚æ•°
        api_key = config.get('new', {}).get('key', '')
        self.llm = ChatOpenAI(
            model_name="new-model",
            temperature=0.7,
            openai_api_key=api_key
        )
    
    def generate(self, prompt: str) -> str:
        response = self.llm.invoke(prompt)
        return response.content
```

### 2. æ·»åŠ åˆ°å·¥å‚ç±»

åœ¨ `src/factory.py` çš„ `LLMFactory` ä¸­æ·»åŠ ï¼š

```python
elif llm_type == "new":
    return NewLLM()
```

## å‚æ•°è¯´æ˜

- `--input_file`: è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆJSONæ ¼å¼ï¼‰
- `--output_dir`: è¾“å‡ºç›®å½•
- `--counselor_type`: å’¨è¯¢å¸ˆç±»å‹ï¼ˆé»˜è®¤ï¼šcactusï¼‰
- `--llm_type`: LLMç±»å‹ï¼ˆchatgpt, llama2, llama3, longemotion, cbtï¼‰
- `--max_turns`: æœ€å¤§å¯¹è¯è½®æ¬¡ï¼ˆé»˜è®¤ï¼š20ï¼‰

## è¾“å‡ºæ ¼å¼

è¾“å‡ºä¸ºJSONæ–‡ä»¶ï¼ŒåŒ…å«ï¼š
- å®¢æˆ·æ•°æ®
- å¯¹è¯å†å²
- å’¨è¯¢å¸ˆç±»å‹å’ŒLLMç±»å‹
- æœ€å¤§è½®æ¬¡

## å¼•ç”¨

```
@misc{lee2024cactus,
      title={Cactus: Towards Psychological Counseling Conversations using Cognitive Behavioral Theory}, 
      author={Suyeon Lee and Sunghwan Kim and Minju Kim and Dongjin Kang and Dongil Yang and Harim Kim and Minseok Kang and Dayi Jung and Min Hee Kim and Seungbeen Lee and Kyoung-Mee Chung and Youngjae Yu and Dongha Lee and Jinyoung Yeo},
      year={2024},
      eprint={2407.03103},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.03103}, 
}
```

## è®¸å¯è¯

GPL-2.0

## é“¾æ¥

åŸå§‹é¡¹ç›®å’Œæ•°æ®é›†ï¼šhttps://github.com/coding-groot/cactus

Hugging Face: https://huggingface.co/collections/DLI-Lab/cactus-towards-psychological-counseling-conversations-6672312f6f64b0d7be75dd0b

