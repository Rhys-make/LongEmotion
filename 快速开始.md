# LongEmotion å¿«é€Ÿå¼€å§‹æŒ‡å—

## ä¸€ã€ç¯å¢ƒå‡†å¤‡ï¼ˆ5 åˆ†é’Ÿï¼‰

### Windows

```powershell
# 1. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
.\venv\Scripts\activate

# 2. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 3. å¦‚æœç½‘ç»œè¾ƒæ…¢ï¼Œä½¿ç”¨å›½å†…é•œåƒ
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
```

### Linux/Mac

```bash
# 1. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate

# 2. å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

## äºŒã€ä¸‹è½½æ•°æ®ï¼ˆ10 åˆ†é’Ÿï¼‰

```bash
# ä¸‹è½½æ‰€æœ‰ä»»åŠ¡çš„æ•°æ®é›†
python scripts/download_dataset.py

# å¦‚æœç½‘ç»œé—®é¢˜ï¼Œä½¿ç”¨é•œåƒ
set HF_ENDPOINT=https://hf-mirror.com  # Windows
export HF_ENDPOINT=https://hf-mirror.com  # Linux/Mac
python scripts/download_dataset.py
```

**æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸‹è½½æˆåŠŸï¼š**

```bash
python scripts/download_dataset.py --verify
```

## ä¸‰ã€è®­ç»ƒæ¨¡å‹ï¼ˆå–å†³äº GPUï¼‰

### å¿«é€Ÿæµ‹è¯•ï¼ˆ10 åˆ†é’Ÿï¼‰

ä»…è®­ç»ƒåˆ†ç±»ä»»åŠ¡ï¼Œä½¿ç”¨å°æ‰¹é‡å’Œå°‘é‡è½®æ•°ï¼š

```bash
python scripts/train_all.py --tasks classification --num_epochs 1 --batch_size 8
```

### å®Œæ•´è®­ç»ƒï¼ˆæ•°å°æ—¶ï¼‰

è®­ç»ƒæ‰€æœ‰ä»»åŠ¡ï¼š

```bash
# CPU è®­ç»ƒï¼ˆæ…¢ï¼‰
python scripts/train_all.py --device cpu --batch_size 4

# GPU è®­ç»ƒï¼ˆå¿«ï¼‰
python scripts/train_all.py --device cuda --batch_size 16
```

### åˆ†åˆ«è®­ç»ƒå„ä»»åŠ¡

```bash
# 1. åˆ†ç±»ä»»åŠ¡ï¼ˆæœ€å¿«ï¼‰
python scripts/train_all.py --tasks classification

# 2. æ£€æµ‹ä»»åŠ¡
python scripts/train_all.py --tasks detection

# 3. æ‘˜è¦ä»»åŠ¡
python scripts/train_all.py --tasks summary

# 4. é—®ç­”ä»»åŠ¡
python scripts/train_all.py --tasks qa

# 5. å¯¹è¯ä»»åŠ¡ï¼ˆéœ€è¦å¤§æ˜¾å­˜ï¼Œå»ºè®®è·³è¿‡æˆ–ä½¿ç”¨å°æ¨¡å‹ï¼‰
# python scripts/train_all.py --tasks conversation --batch_size 2
```

## å››ã€ç”Ÿæˆæ¨ç†ç»“æœï¼ˆ10 åˆ†é’Ÿï¼‰

```bash
# æ¨ç†æ‰€æœ‰ä»»åŠ¡
python scripts/inference_all.py

# æ¨ç†ç‰¹å®šä»»åŠ¡
python scripts/inference_all.py --tasks classification detection
```

**ç»“æœæ–‡ä»¶ä½äº `results/` ç›®å½•ï¼š**

- `classification_test.jsonl`
- `detection_test.jsonl`
- `conversation_test.jsonl`
- `summary_test.jsonl`
- `qa_test.jsonl`

## äº”ã€å¯åŠ¨ API æœåŠ¡ï¼ˆ1 åˆ†é’Ÿï¼‰

```bash
cd api
python main.py
```

**è®¿é—®ï¼š**

- API æœåŠ¡: http://localhost:8000
- API æ–‡æ¡£: http://localhost:8000/docs

**æµ‹è¯• APIï¼š**

```bash
# Windows PowerShell
Invoke-WebRequest -Uri "http://localhost:8000/classify" -Method POST -ContentType "application/json" -Body '{"text":"ä»Šå¤©çœŸå¼€å¿ƒï¼"}'

# Linux/Mac
curl -X POST "http://localhost:8000/classify" -H "Content-Type: application/json" -d '{"text":"ä»Šå¤©çœŸå¼€å¿ƒï¼"}'
```

æˆ–è€…ä½¿ç”¨ Pythonï¼š

```python
import requests

response = requests.post(
    "http://localhost:8000/classify",
    json={"text": "ä»Šå¤©çœŸå¼€å¿ƒï¼"}
)
print(response.json())
```

## å…­ã€å¸¸è§é—®é¢˜

### 1. ç½‘ç»œé—®é¢˜ï¼ˆä¸‹è½½æ¨¡å‹/æ•°æ®é›†å¤±è´¥ï¼‰

```bash
# è®¾ç½® Hugging Face é•œåƒ
set HF_ENDPOINT=https://hf-mirror.com  # Windows
export HF_ENDPOINT=https://hf-mirror.com  # Linux/Mac
```

### 2. æ˜¾å­˜ä¸è¶³ï¼ˆCUDA out of memoryï¼‰

**æ–¹æ¡ˆ 1: å‡å°æ‰¹é‡å¤§å°**
```bash
python scripts/train_all.py --batch_size 4
```

**æ–¹æ¡ˆ 2: ä½¿ç”¨ CPU**
```bash
python scripts/train_all.py --device cpu
```

**æ–¹æ¡ˆ 3: åªè®­ç»ƒå°æ¨¡å‹**
```bash
# è·³è¿‡å¯¹è¯å’Œæ‘˜è¦ä»»åŠ¡
python scripts/train_all.py --tasks classification detection qa
```

### 3. æ¨¡å—å¯¼å…¥é”™è¯¯

ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œè„šæœ¬ï¼š

```bash
# æŸ¥çœ‹å½“å‰ç›®å½•
pwd  # Linux/Mac
cd   # Windows

# åº”è¯¥åŒ…å«è¿™äº›æ–‡ä»¶å¤¹
ls  # åº”è¯¥çœ‹åˆ°: models/ utils/ scripts/ api/
```

### 4. æ‰¾ä¸åˆ°æ•°æ®é›†

ç¡®ä¿æ•°æ®å·²ä¸‹è½½ï¼š

```bash
python scripts/download_dataset.py --verify
```

## ä¸ƒã€é¡¹ç›®æ–‡ä»¶ç»“æ„

```
LongEmotion/
â”œâ”€â”€ models/           â† æ¨¡å‹å®šä¹‰
â”œâ”€â”€ utils/            â† å·¥å…·å‡½æ•°
â”œâ”€â”€ scripts/          â† è®­ç»ƒå’Œæ¨ç†è„šæœ¬
â”œâ”€â”€ api/              â† FastAPI æœåŠ¡
â”œâ”€â”€ data/             â† æ•°æ®é›†ï¼ˆä¸‹è½½åç”Ÿæˆï¼‰
â”œâ”€â”€ checkpoints/      â† è®­ç»ƒçš„æ¨¡å‹ï¼ˆè®­ç»ƒåç”Ÿæˆï¼‰
â”œâ”€â”€ results/          â† æ¨ç†ç»“æœï¼ˆæ¨ç†åç”Ÿæˆï¼‰
â”œâ”€â”€ config.py         â† é…ç½®æ–‡ä»¶
â”œâ”€â”€ run_example.py    â† ç¤ºä¾‹ä»£ç 
â””â”€â”€ requirements.txt  â† ä¾èµ–åˆ—è¡¨
```

## å…«ã€å®Œæ•´æµç¨‹ï¼ˆä¸€æ¡é¾™ï¼‰

```bash
# 1. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 2. ä¸‹è½½æ•°æ®
python scripts/download_dataset.py

# 3. è®­ç»ƒæ¨¡å‹ï¼ˆé€‰æ‹©ä¸€ä¸ªï¼‰
python scripts/train_all.py --tasks classification  # å¿«é€Ÿæµ‹è¯•
# python scripts/train_all.py  # å®Œæ•´è®­ç»ƒ

# 4. æ¨ç†
python scripts/inference_all.py

# 5. å¯åŠ¨æœåŠ¡
cd api
python main.py
```

## ä¹ã€éªŒè¯ç»“æœ

### æ£€æŸ¥è®­ç»ƒç»“æœ

```bash
# æŸ¥çœ‹æ¨¡å‹æ–‡ä»¶
ls checkpoints/classification/best_model/  # Linux/Mac
dir checkpoints\classification\best_model\  # Windows

# åº”è¯¥åŒ…å«: config.json, pytorch_model.bin ç­‰
```

### æ£€æŸ¥æ¨ç†ç»“æœ

```bash
# æŸ¥çœ‹ç»“æœæ–‡ä»¶
head results/classification_test.jsonl  # Linux/Mac
type results\classification_test.jsonl | more  # Windows

# åº”è¯¥æ˜¯ JSONL æ ¼å¼çš„é¢„æµ‹ç»“æœ
```

### æµ‹è¯• API

æ‰“å¼€æµè§ˆå™¨è®¿é—®ï¼šhttp://localhost:8000/docs

å¯ä»¥åœ¨é¡µé¢ä¸Šç›´æ¥æµ‹è¯•å„ä¸ª API æ¥å£ã€‚

## åã€æäº¤åˆ°æ¯”èµ›

### 1. å‡†å¤‡æäº¤æ–‡ä»¶

```bash
# æ¨ç†ç»“æœï¼ˆ5ä¸ªæ–‡ä»¶ï¼‰
results/classification_test.jsonl
results/detection_test.jsonl
results/conversation_test.jsonl
results/summary_test.jsonl
results/qa_test.jsonl
```

### 2. ä¸Šä¼ æ¨¡å‹åˆ° Hugging Face

```python
from huggingface_hub import HfApi

api = HfApi()

# ä¸Šä¼ åˆ†ç±»æ¨¡å‹
api.upload_folder(
    folder_path="./checkpoints/classification/best_model",
    repo_id="your-username/longemotion-classification",
    repo_type="model"
)
```

### 3. ä¸Šä¼ ä»£ç åˆ° GitHub

```bash
git init
git add .
git commit -m "LongEmotion å®Œæ•´æ–¹æ¡ˆ"
git remote add origin your-repo-url
git push -u origin main
```

## éœ€è¦å¸®åŠ©ï¼Ÿ

- æŸ¥çœ‹è¯¦ç»†æ–‡æ¡£: `README.md`
- è¿è¡Œç¤ºä¾‹ä»£ç : `python run_example.py`
- æŸ¥çœ‹é…ç½®é€‰é¡¹: `python scripts/train_all.py --help`

**ç¥ä½ æ¯”èµ›é¡ºåˆ©ï¼** ğŸ‰

